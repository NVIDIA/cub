<!-- HTML header for doxygen 1.8.3.1-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.4"/>
<title>CUB: cub::DeviceReduce Struct Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="extra_stylesheet.css" rel="stylesheet" type="text/css"/>
<link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-38890655-1']);
  _gaq.push(['_trackPageview']);
  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">CUB
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.4 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="examples.html"><span>Examples</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Friends</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(10)"><span class="SelectionMark">&#160;</span>Groups</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacecub.html">cub</a></li><li class="navelem"><a class="el" href="structcub_1_1_device_reduce.html">DeviceReduce</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-static-methods">Static Public Methods</a> &#124;
<a href="structcub_1_1_device_reduce-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">cub::DeviceReduce Struct Reference<div class="ingroups"><a class="el" href="group___device_module.html">Device-wide</a></div></div>  </div>
</div><!--header-->
<div class="contents">
<a name="details" id="details"></a><h2 class="groupheader">Detailed description</h2>
<div class="textblock"><p><a class="el" href="structcub_1_1_device_reduce.html" title="DeviceReduce provides device-wide, parallel operations for computing a reduction across a sequence of...">DeviceReduce</a> provides device-wide, parallel operations for computing a reduction across a sequence of data items residing within global memory. </p>
<div class="image">
<img src="reduce_logo.png" alt="reduce_logo.png"/>
<div class="caption">
.</div></div>
 <dl class="section user"><dt>Overview</dt><dd>A <a href="http://en.wikipedia.org/wiki/Reduce_(higher-order_function)"><em>reduction</em></a> (or <em>fold</em>) uses a binary combining operator to compute a single aggregate from a sequence of input elements.</dd></dl>
<dl class="section user"><dt>Usage Considerations</dt><dd><ul>
<li><em>Dynamic parallelism</em>. <a class="el" href="structcub_1_1_device_reduce.html" title="DeviceReduce provides device-wide, parallel operations for computing a reduction across a sequence of...">DeviceReduce</a> methods can be called within kernel code on devices in which CUDA dynamic parallelism is supported. When calling these methods from kernel code, be sure to define the <code>CUB_CDP</code> macro in your compiler's macro definitions.</li>
</ul>
</dd></dl>
<dl class="section user"><dt>Performance</dt><dd>The work-complexity of reduction, reduce-by-key, and run-length encode as a function of input size is linear, resulting in performance throughput that plateaus with problem sizes large enough to saturate the GPU.</dd></dl>
<dl class="section user"><dt></dt><dd>The following chart illustrates <a class="el" href="structcub_1_1_device_reduce.html#ae38bbfec0b058564ee966c9451fabbcc" title="Computes a device-wide sum using the addition (&#39;+&#39;) operator. ">DeviceReduce::Sum</a> performance across different CUDA architectures for <code>int32</code> keys.</dd></dl>
<div class="image">
<img src="reduce_int32.png" alt="reduce_int32.png"/>
</div>
<dl class="section user"><dt></dt><dd>The following chart illustrates <a class="el" href="structcub_1_1_device_reduce.html#a62400e8632002f3ba601d4392b997bc7" title="Reduces segments of values, where segments are demarcated by corresponding runs of identical keys...">DeviceReduce::ReduceByKey</a> (summation) performance across different CUDA architectures for <code>fp32</code> values. Segments are identified by <code>int32</code> keys, and have lengths uniformly sampled from [1,1000].</dd></dl>
<div class="image">
<img src="reduce_by_key_fp32_len_500.png" alt="reduce_by_key_fp32_len_500.png"/>
</div>
<dl class="section user"><dt></dt><dd>The following chart illustrates <a class="el" href="structcub_1_1_device_reduce.html#ac563c98fb1d6cde7d4365bc34f6b698d" title="Counts the segment lengths in the sequence d_in, where segments are demarcated by runs of identical v...">DeviceReduce::RunLengthEncode</a> performance across different CUDA architectures for <code>int32</code> items. Segments have lengths uniformly sampled from [1,1000].</dd></dl>
<div class="image">
<img src="rle_int32_len_500.png" alt="rle_int32_len_500.png"/>
</div>
<dl class="section user"><dt></dt><dd>Performance plots for other scenarios can be found in the detailed method descriptions below. </dd></dl>

<p>Definition at line <a class="el" href="device__reduce_8cuh_source.html#l00089">89</a> of file <a class="el" href="device__reduce_8cuh_source.html">device_reduce.cuh</a>.</p>
</div><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Methods</h2></td></tr>
<tr class="memitem:a2e7bb79308e1135b77be4cf15ea993ee"><td class="memTemplParams" colspan="2">template&lt;typename InputIterator , typename OutputIterator , typename ReductionOp &gt; </td></tr>
<tr class="memitem:a2e7bb79308e1135b77be4cf15ea993ee"><td class="memTemplItemLeft" align="right" valign="top">__host__ static __device__ <br class="typebreak"/>
cudaError_t&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="structcub_1_1_device_reduce.html#a2e7bb79308e1135b77be4cf15ea993ee">Reduce</a> (void *d_temp_storage, size_t &amp;temp_storage_bytes, InputIterator d_in, OutputIterator d_out, int num_items, ReductionOp reduction_op, cudaStream_t stream=0, bool debug_synchronous=false)</td></tr>
<tr class="memdesc:a2e7bb79308e1135b77be4cf15ea993ee"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes a device-wide reduction using the specified binary <code>reduction_op</code> functor.  <a href="#a2e7bb79308e1135b77be4cf15ea993ee">More...</a><br/></td></tr>
<tr class="separator:a2e7bb79308e1135b77be4cf15ea993ee"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae38bbfec0b058564ee966c9451fabbcc"><td class="memTemplParams" colspan="2">template&lt;typename InputIterator , typename OutputIterator &gt; </td></tr>
<tr class="memitem:ae38bbfec0b058564ee966c9451fabbcc"><td class="memTemplItemLeft" align="right" valign="top">__host__ static __device__ <br class="typebreak"/>
cudaError_t&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="structcub_1_1_device_reduce.html#ae38bbfec0b058564ee966c9451fabbcc">Sum</a> (void *d_temp_storage, size_t &amp;temp_storage_bytes, InputIterator d_in, OutputIterator d_out, int num_items, cudaStream_t stream=0, bool debug_synchronous=false)</td></tr>
<tr class="memdesc:ae38bbfec0b058564ee966c9451fabbcc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes a device-wide sum using the addition ('+') operator.  <a href="#ae38bbfec0b058564ee966c9451fabbcc">More...</a><br/></td></tr>
<tr class="separator:ae38bbfec0b058564ee966c9451fabbcc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adada0367d1c362e753ebf1af1045e854"><td class="memTemplParams" colspan="2">template&lt;typename InputIterator , typename OutputIterator &gt; </td></tr>
<tr class="memitem:adada0367d1c362e753ebf1af1045e854"><td class="memTemplItemLeft" align="right" valign="top">__host__ static __device__ <br class="typebreak"/>
cudaError_t&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="structcub_1_1_device_reduce.html#adada0367d1c362e753ebf1af1045e854">Min</a> (void *d_temp_storage, size_t &amp;temp_storage_bytes, InputIterator d_in, OutputIterator d_out, int num_items, cudaStream_t stream=0, bool debug_synchronous=false)</td></tr>
<tr class="memdesc:adada0367d1c362e753ebf1af1045e854"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes a device-wide minimum using the less-than ('&lt;') operator.  <a href="#adada0367d1c362e753ebf1af1045e854">More...</a><br/></td></tr>
<tr class="separator:adada0367d1c362e753ebf1af1045e854"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3dc1b284c8828d1e51da587a090a140"><td class="memTemplParams" colspan="2">template&lt;typename InputIterator , typename OutputIterator &gt; </td></tr>
<tr class="memitem:af3dc1b284c8828d1e51da587a090a140"><td class="memTemplItemLeft" align="right" valign="top">__host__ static __device__ <br class="typebreak"/>
cudaError_t&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="structcub_1_1_device_reduce.html#af3dc1b284c8828d1e51da587a090a140">ArgMin</a> (void *d_temp_storage, size_t &amp;temp_storage_bytes, InputIterator d_in, OutputIterator d_out, int num_items, cudaStream_t stream=0, bool debug_synchronous=false)</td></tr>
<tr class="memdesc:af3dc1b284c8828d1e51da587a090a140"><td class="mdescLeft">&#160;</td><td class="mdescRight">Finds the first device-wide minimum using the less-than ('&lt;') operator, also returning the index of that item.  <a href="#af3dc1b284c8828d1e51da587a090a140">More...</a><br/></td></tr>
<tr class="separator:af3dc1b284c8828d1e51da587a090a140"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a335a77d51f436c8840b50f53cab137a5"><td class="memTemplParams" colspan="2">template&lt;typename InputIterator , typename OutputIterator &gt; </td></tr>
<tr class="memitem:a335a77d51f436c8840b50f53cab137a5"><td class="memTemplItemLeft" align="right" valign="top">__host__ static __device__ <br class="typebreak"/>
cudaError_t&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="structcub_1_1_device_reduce.html#a335a77d51f436c8840b50f53cab137a5">Max</a> (void *d_temp_storage, size_t &amp;temp_storage_bytes, InputIterator d_in, OutputIterator d_out, int num_items, cudaStream_t stream=0, bool debug_synchronous=false)</td></tr>
<tr class="memdesc:a335a77d51f436c8840b50f53cab137a5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Computes a device-wide maximum using the greater-than ('&gt;') operator.  <a href="#a335a77d51f436c8840b50f53cab137a5">More...</a><br/></td></tr>
<tr class="separator:a335a77d51f436c8840b50f53cab137a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7524b86cae1cb19d7a8899141d8c9908"><td class="memTemplParams" colspan="2">template&lt;typename InputIterator , typename OutputIterator &gt; </td></tr>
<tr class="memitem:a7524b86cae1cb19d7a8899141d8c9908"><td class="memTemplItemLeft" align="right" valign="top">__host__ static __device__ <br class="typebreak"/>
cudaError_t&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="structcub_1_1_device_reduce.html#a7524b86cae1cb19d7a8899141d8c9908">ArgMax</a> (void *d_temp_storage, size_t &amp;temp_storage_bytes, InputIterator d_in, OutputIterator d_out, int num_items, cudaStream_t stream=0, bool debug_synchronous=false)</td></tr>
<tr class="memdesc:a7524b86cae1cb19d7a8899141d8c9908"><td class="mdescLeft">&#160;</td><td class="mdescRight">Finds the first device-wide maximum using the greater-than ('&gt;') operator, also returning the index of that item.  <a href="#a7524b86cae1cb19d7a8899141d8c9908">More...</a><br/></td></tr>
<tr class="separator:a7524b86cae1cb19d7a8899141d8c9908"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62400e8632002f3ba601d4392b997bc7"><td class="memTemplParams" colspan="2">template&lt;typename KeyInputIterator , typename KeyOutputIterator , typename ValueInputIterator , typename ValueOutputIterator , typename NumSegmentsIterator , typename ReductionOp &gt; </td></tr>
<tr class="memitem:a62400e8632002f3ba601d4392b997bc7"><td class="memTemplItemLeft" align="right" valign="top">__host__ __device__ static <br class="typebreak"/>
__forceinline__ cudaError_t&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="structcub_1_1_device_reduce.html#a62400e8632002f3ba601d4392b997bc7">ReduceByKey</a> (void *d_temp_storage, size_t &amp;temp_storage_bytes, KeyInputIterator d_keys_in, KeyOutputIterator d_keys_out, ValueInputIterator d_values_in, ValueOutputIterator d_values_out, NumSegmentsIterator d_num_segments, ReductionOp reduction_op, int num_items, cudaStream_t stream=0, bool debug_synchronous=false)</td></tr>
<tr class="memdesc:a62400e8632002f3ba601d4392b997bc7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reduces segments of values, where segments are demarcated by corresponding runs of identical keys.  <a href="#a62400e8632002f3ba601d4392b997bc7">More...</a><br/></td></tr>
<tr class="separator:a62400e8632002f3ba601d4392b997bc7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac563c98fb1d6cde7d4365bc34f6b698d"><td class="memTemplParams" colspan="2">template&lt;typename InputIterator , typename OutputIterator , typename CountsOutputIterator , typename NumSegmentsIterator &gt; </td></tr>
<tr class="memitem:ac563c98fb1d6cde7d4365bc34f6b698d"><td class="memTemplItemLeft" align="right" valign="top">__host__ __device__ static <br class="typebreak"/>
__forceinline__ cudaError_t&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="structcub_1_1_device_reduce.html#ac563c98fb1d6cde7d4365bc34f6b698d">RunLengthEncode</a> (void *d_temp_storage, size_t &amp;temp_storage_bytes, InputIterator d_in, OutputIterator d_compacted_out, CountsOutputIterator d_counts_out, NumSegmentsIterator d_num_segments, int num_items, cudaStream_t stream=0, bool debug_synchronous=false)</td></tr>
<tr class="memdesc:ac563c98fb1d6cde7d4365bc34f6b698d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Counts the segment lengths in the sequence <code>d_in</code>, where segments are demarcated by runs of identical values.  <a href="#ac563c98fb1d6cde7d4365bc34f6b698d">More...</a><br/></td></tr>
<tr class="separator:ac563c98fb1d6cde7d4365bc34f6b698d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Member Function Documentation</h2>
<a class="anchor" id="a2e7bb79308e1135b77be4cf15ea993ee"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename InputIterator , typename OutputIterator , typename ReductionOp &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">__host__ static __device__ cudaError_t cub::DeviceReduce::Reduce </td>
          <td>(</td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>d_temp_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t &amp;&#160;</td>
          <td class="paramname"><em>temp_storage_bytes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>d_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">OutputIterator&#160;</td>
          <td class="paramname"><em>d_out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ReductionOp&#160;</td>
          <td class="paramname"><em>reduction_op</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>debug_synchronous</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes a device-wide reduction using the specified binary <code>reduction_op</code> functor. </p>
<dl class="section user"><dt></dt><dd><ul>
<li>Does not support non-commutative reduction operators.</li>
<li>This operation requires an allocation of temporary device storage. When <code>d_temp_storage</code> is NULL, no work is done and the required allocation size is returned in <code>temp_storage_bytes</code>.</li>
<li>When calling this method from kernel code, be sure to define the <code>CUB_CDP</code> macro in your compiler's macro definitions.</li>
</ul>
</dd></dl>
<dl class="section user"><dt>Performance</dt><dd>Performance is typically similar to <a class="el" href="structcub_1_1_device_reduce.html#ae38bbfec0b058564ee966c9451fabbcc" title="Computes a device-wide sum using the addition (&#39;+&#39;) operator. ">DeviceReduce::Sum</a>.</dd></dl>
<dl class="section user"><dt>Snippet</dt><dd>The code snippet below illustrates a custom min reduction of a device vector of <code>int</code> items. </dd></dl>
<dl class="section user"><dt></dt><dd><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="cub_8cuh.html">cub/cub.cuh</a>&gt;</span>   <span class="comment">// or equivalently &lt;cub/device/device_radix_sort.cuh&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// CustomMin functor</span></div>
<div class="line"><span class="keyword">struct </span>CustomMin</div>
<div class="line">{</div>
<div class="line">    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="line">    __host__ __device__ __forceinline__</div>
<div class="line">    T operator()(<span class="keyword">const</span> T &amp;a, <span class="keyword">const</span> T &amp;b)<span class="keyword"> const </span>{</div>
<div class="line">        <span class="keywordflow">return</span> (b &lt; a) ? b : a;</div>
<div class="line">    }</div>
<div class="line">};</div>
<div class="line"></div>
<div class="line"><span class="comment">// Declare, allocate, and initialize device pointers for input and output</span></div>
<div class="line"><span class="keywordtype">int</span>          num_items;  <span class="comment">// e.g., 7</span></div>
<div class="line"><span class="keywordtype">int</span>          *d_in;      <span class="comment">// e.g., [8, 6, 7, 5, 3, 0, 9]</span></div>
<div class="line"><span class="keywordtype">int</span>          *d_out;     <span class="comment">// e.g., [ ]</span></div>
<div class="line">CustomMin    min_op;</div>
<div class="line">...</div>
<div class="line"></div>
<div class="line"><span class="comment">// Determine temporary device storage requirements</span></div>
<div class="line">void     *d_temp_storage = NULL;</div>
<div class="line"><span class="keywordtype">size_t</span>   temp_storage_bytes = 0;</div>
<div class="line"><a class="code" href="structcub_1_1_device_reduce.html#a2e7bb79308e1135b77be4cf15ea993ee" title="Computes a device-wide reduction using the specified binary reduction_op functor. ...">cub::DeviceReduce::Reduce</a>(d_temp_storage, temp_storage_bytes, d_in, d_out, num_items, min_op);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Allocate temporary storage</span></div>
<div class="line">cudaMalloc(&amp;d_temp_storage, temp_storage_bytes);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Run reduction</span></div>
<div class="line"><a class="code" href="structcub_1_1_device_reduce.html#a2e7bb79308e1135b77be4cf15ea993ee" title="Computes a device-wide reduction using the specified binary reduction_op functor. ...">cub::DeviceReduce::Reduce</a>(d_temp_storage, temp_storage_bytes, d_in, d_out, num_items, min_op);</div>
<div class="line"></div>
<div class="line"><span class="comment">// d_out &lt;-- [0]</span></div>
</div><!-- fragment --></dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> Random-access input iterator type for reading input items (may be a simple pointer type) </td></tr>
    <tr><td class="paramname">OutputIterator</td><td><b>[inferred]</b> Output iterator type for recording the reduced aggregate (may be a simple pointer type) </td></tr>
    <tr><td class="paramname">ReductionOp</td><td><b>[inferred]</b> Binary reduction functor type having member <code>T operator()(const T &amp;a, const T &amp;b)</code> </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">d_temp_storage</td><td>Device allocation of temporary storage. When NULL, the required allocation size is written to <code>temp_storage_bytes</code> and no work is done. </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">temp_storage_bytes</td><td>Reference to size in bytes of <code>d_temp_storage</code> allocation </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">d_in</td><td>Pointer to the input sequence of data items </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">d_out</td><td>Pointer to the output aggregate </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_items</td><td>Total number of input items (i.e., length of <code>d_in</code>) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">reduction_op</td><td>Binary reduction functor (e.g., an instance of <a class="el" href="structcub_1_1_sum.html" title="Default sum functor. ">cub::Sum</a>, <a class="el" href="structcub_1_1_min.html" title="Default min functor. ">cub::Min</a>, <a class="el" href="structcub_1_1_max.html" title="Default max functor. ">cub::Max</a>, etc.) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stream</td><td><b>[optional]</b> CUDA stream to launch kernels within. Default is stream<sub>0</sub>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">debug_synchronous</td><td><b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors. Also causes launch configurations to be printed to the console. Default is <code>false</code>. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="device__reduce_8cuh_source.html#l00149">149</a> of file <a class="el" href="device__reduce_8cuh_source.html">device_reduce.cuh</a>.</p>

</div>
</div>
<a class="anchor" id="ae38bbfec0b058564ee966c9451fabbcc"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename InputIterator , typename OutputIterator &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">__host__ static __device__ cudaError_t cub::DeviceReduce::Sum </td>
          <td>(</td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>d_temp_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t &amp;&#160;</td>
          <td class="paramname"><em>temp_storage_bytes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>d_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">OutputIterator&#160;</td>
          <td class="paramname"><em>d_out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>debug_synchronous</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes a device-wide sum using the addition ('+') operator. </p>
<dl class="section user"><dt></dt><dd><ul>
<li>Does not support non-commutative reduction operators.</li>
<li>This operation requires an allocation of temporary device storage. When <code>d_temp_storage</code> is NULL, no work is done and the required allocation size is returned in <code>temp_storage_bytes</code>.</li>
<li>When calling this method from kernel code, be sure to define the <code>CUB_CDP</code> macro in your compiler's macro definitions.</li>
</ul>
</dd></dl>
<dl class="section user"><dt>Performance</dt><dd>The following charts illustrate saturated reduction (sum) performance across different CUDA architectures for <code>int32</code> and <code>int64</code> items, respectively.</dd></dl>
<div class="image">
<img src="reduce_int32.png" alt="reduce_int32.png"/>
</div>
 <div class="image">
<img src="reduce_int64.png" alt="reduce_int64.png"/>
</div>
<dl class="section user"><dt>Snippet</dt><dd>The code snippet below illustrates the sum reduction of a device vector of <code>int</code> items. </dd></dl>
<dl class="section user"><dt></dt><dd><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="cub_8cuh.html">cub/cub.cuh</a>&gt;</span>   <span class="comment">// or equivalently &lt;cub/device/device_radix_sort.cuh&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// Declare, allocate, and initialize device pointers for input and output</span></div>
<div class="line"><span class="keywordtype">int</span>  num_items;      <span class="comment">// e.g., 7</span></div>
<div class="line"><span class="keywordtype">int</span>  *d_in;          <span class="comment">// e.g., [8, 6, 7, 5, 3, 0, 9]</span></div>
<div class="line"><span class="keywordtype">int</span>  *d_out;         <span class="comment">// e.g., [ ]</span></div>
<div class="line">...</div>
<div class="line"></div>
<div class="line"><span class="comment">// Determine temporary device storage requirements</span></div>
<div class="line">void     *d_temp_storage = NULL;</div>
<div class="line"><span class="keywordtype">size_t</span>   temp_storage_bytes = 0;</div>
<div class="line"><a class="code" href="structcub_1_1_device_reduce.html#ae38bbfec0b058564ee966c9451fabbcc" title="Computes a device-wide sum using the addition (&#39;+&#39;) operator. ">cub::DeviceReduce::Sum</a>(d_temp_storage, temp_storage_bytes, d_in, d_sum, num_items);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Allocate temporary storage</span></div>
<div class="line">cudaMalloc(&amp;d_temp_storage, temp_storage_bytes);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Run sum-reduction</span></div>
<div class="line"><a class="code" href="structcub_1_1_device_reduce.html#ae38bbfec0b058564ee966c9451fabbcc" title="Computes a device-wide sum using the addition (&#39;+&#39;) operator. ">cub::DeviceReduce::Sum</a>(d_temp_storage, temp_storage_bytes, d_in, d_sum, num_items);</div>
<div class="line"></div>
<div class="line"><span class="comment">// d_out &lt;-- [38]</span></div>
</div><!-- fragment --></dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> Random-access input iterator type for reading input items (may be a simple pointer type) </td></tr>
    <tr><td class="paramname">OutputIterator</td><td><b>[inferred]</b> Output iterator type for recording the reduced aggregate (may be a simple pointer type) </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">d_temp_storage</td><td>Device allocation of temporary storage. When NULL, the required allocation size is written to <code>temp_storage_bytes</code> and no work is done. </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">temp_storage_bytes</td><td>Reference to size in bytes of <code>d_temp_storage</code> allocation </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">d_in</td><td>Pointer to the input sequence of data items </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">d_out</td><td>Pointer to the output aggregate </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_items</td><td>Total number of input items (i.e., length of <code>d_in</code>) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stream</td><td><b>[optional]</b> CUDA stream to launch kernels within. Default is stream<sub>0</sub>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">debug_synchronous</td><td><b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors. Also causes launch configurations to be printed to the console. Default is <code>false</code>. </td></tr>
  </table>
  </dd>
</dl>
<dl><dt><b>Examples: </b></dt><dd><a class="el" href="example_device_reduce_8cu-example.html#a2">example_device_reduce.cu</a>.</dd>
</dl>
<p>Definition at line <a class="el" href="device__reduce_8cuh_source.html#l00226">226</a> of file <a class="el" href="device__reduce_8cuh_source.html">device_reduce.cuh</a>.</p>

</div>
</div>
<a class="anchor" id="adada0367d1c362e753ebf1af1045e854"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename InputIterator , typename OutputIterator &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">__host__ static __device__ cudaError_t cub::DeviceReduce::Min </td>
          <td>(</td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>d_temp_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t &amp;&#160;</td>
          <td class="paramname"><em>temp_storage_bytes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>d_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">OutputIterator&#160;</td>
          <td class="paramname"><em>d_out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>debug_synchronous</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes a device-wide minimum using the less-than ('&lt;') operator. </p>
<dl class="section user"><dt></dt><dd><ul>
<li>Does not support non-commutative minimum operators.</li>
<li>This operation requires an allocation of temporary device storage. When <code>d_temp_storage</code> is NULL, no work is done and the required allocation size is returned in <code>temp_storage_bytes</code>.</li>
<li>When calling this method from kernel code, be sure to define the <code>CUB_CDP</code> macro in your compiler's macro definitions.</li>
</ul>
</dd></dl>
<dl class="section user"><dt>Performance</dt><dd>Performance is typically similar to <a class="el" href="structcub_1_1_device_reduce.html#ae38bbfec0b058564ee966c9451fabbcc" title="Computes a device-wide sum using the addition (&#39;+&#39;) operator. ">DeviceReduce::Sum</a>.</dd></dl>
<dl class="section user"><dt>Snippet</dt><dd>The code snippet below illustrates the min-reduction of a device vector of <code>int</code> items. </dd></dl>
<dl class="section user"><dt></dt><dd><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="cub_8cuh.html">cub/cub.cuh</a>&gt;</span>   <span class="comment">// or equivalently &lt;cub/device/device_radix_sort.cuh&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// Declare, allocate, and initialize device pointers for input and output</span></div>
<div class="line"><span class="keywordtype">int</span>  num_items;      <span class="comment">// e.g., 7</span></div>
<div class="line"><span class="keywordtype">int</span>  *d_in;          <span class="comment">// e.g., [8, 6, 7, 5, 3, 0, 9]</span></div>
<div class="line"><span class="keywordtype">int</span>  *d_out;         <span class="comment">// e.g., [ ]</span></div>
<div class="line">...</div>
<div class="line"></div>
<div class="line"><span class="comment">// Determine temporary device storage requirements</span></div>
<div class="line">void     *d_temp_storage = NULL;</div>
<div class="line"><span class="keywordtype">size_t</span>   temp_storage_bytes = 0;</div>
<div class="line"><a class="code" href="structcub_1_1_device_reduce.html#adada0367d1c362e753ebf1af1045e854" title="Computes a device-wide minimum using the less-than (&#39;&lt;&#39;) operator. ">cub::DeviceReduce::Min</a>(d_temp_storage, temp_storage_bytes, d_in, d_min, num_items);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Allocate temporary storage</span></div>
<div class="line">cudaMalloc(&amp;d_temp_storage, temp_storage_bytes);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Run min-reduction</span></div>
<div class="line"><a class="code" href="structcub_1_1_device_reduce.html#adada0367d1c362e753ebf1af1045e854" title="Computes a device-wide minimum using the less-than (&#39;&lt;&#39;) operator. ">cub::DeviceReduce::Min</a>(d_temp_storage, temp_storage_bytes, d_in, d_min, num_items);</div>
<div class="line"></div>
<div class="line"><span class="comment">// d_out &lt;-- [0]</span></div>
</div><!-- fragment --></dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> Random-access input iterator type for reading input items (may be a simple pointer type) </td></tr>
    <tr><td class="paramname">OutputIterator</td><td><b>[inferred]</b> Output iterator type for recording the reduced aggregate (may be a simple pointer type) </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">d_temp_storage</td><td>Device allocation of temporary storage. When NULL, the required allocation size is written to <code>temp_storage_bytes</code> and no work is done. </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">temp_storage_bytes</td><td>Reference to size in bytes of <code>d_temp_storage</code> allocation </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">d_in</td><td>Pointer to the input sequence of data items </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">d_out</td><td>Pointer to the output aggregate </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_items</td><td>Total number of input items (i.e., length of <code>d_in</code>) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stream</td><td><b>[optional]</b> CUDA stream to launch kernels within. Default is stream<sub>0</sub>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">debug_synchronous</td><td><b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors. Also causes launch configurations to be printed to the console. Default is <code>false</code>. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="device__reduce_8cuh_source.html#l00298">298</a> of file <a class="el" href="device__reduce_8cuh_source.html">device_reduce.cuh</a>.</p>

</div>
</div>
<a class="anchor" id="af3dc1b284c8828d1e51da587a090a140"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename InputIterator , typename OutputIterator &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">__host__ static __device__ cudaError_t cub::DeviceReduce::ArgMin </td>
          <td>(</td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>d_temp_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t &amp;&#160;</td>
          <td class="paramname"><em>temp_storage_bytes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>d_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">OutputIterator&#160;</td>
          <td class="paramname"><em>d_out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>debug_synchronous</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Finds the first device-wide minimum using the less-than ('&lt;') operator, also returning the index of that item. </p>
<dl class="section user"><dt></dt><dd>Assuming the input <code>d_in</code> has value type <code>T</code>, the output <code>d_out</code> must have value type <code>ItemOffsetPair&lt;T, int&gt;</code>. The minimum value is written to <code>d_out.value</code> and its location in the input array is written to <code>d_out.offset</code>.</dd></dl>
<dl class="section user"><dt></dt><dd><ul>
<li>Does not support non-commutative minimum operators.</li>
<li>This operation requires an allocation of temporary device storage. When <code>d_temp_storage</code> is NULL, no work is done and the required allocation size is returned in <code>temp_storage_bytes</code>.</li>
<li>When calling this method from kernel code, be sure to define the <code>CUB_CDP</code> macro in your compiler's macro definitions.</li>
</ul>
</dd></dl>
<dl class="section user"><dt>Performance</dt><dd>Performance is typically similar to <a class="el" href="structcub_1_1_device_reduce.html#ae38bbfec0b058564ee966c9451fabbcc" title="Computes a device-wide sum using the addition (&#39;+&#39;) operator. ">DeviceReduce::Sum</a>.</dd></dl>
<dl class="section user"><dt>Snippet</dt><dd>The code snippet below illustrates the argmin-reduction of a device vector of <code>int</code> items. </dd></dl>
<dl class="section user"><dt></dt><dd><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="cub_8cuh.html">cub/cub.cuh</a>&gt;</span>   <span class="comment">// or equivalently &lt;cub/device/device_radix_sort.cuh&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// Declare, allocate, and initialize device pointers for input and output</span></div>
<div class="line"><span class="keywordtype">int</span>                      num_items;      <span class="comment">// e.g., 7</span></div>
<div class="line"><span class="keywordtype">int</span>                      *d_in;          <span class="comment">// e.g., [8, 6, 7, 5, 3, 0, 9]</span></div>
<div class="line">ItemOffsetPair&lt;int, int&gt; *d_out;         <span class="comment">// e.g., [{ , }]</span></div>
<div class="line">...</div>
<div class="line"></div>
<div class="line"><span class="comment">// Determine temporary device storage requirements</span></div>
<div class="line">void     *d_temp_storage = NULL;</div>
<div class="line"><span class="keywordtype">size_t</span>   temp_storage_bytes = 0;</div>
<div class="line"><a class="code" href="structcub_1_1_device_reduce.html#af3dc1b284c8828d1e51da587a090a140" title="Finds the first device-wide minimum using the less-than (&#39;&lt;&#39;) operator, also returning the index o...">cub::DeviceReduce::ArgMin</a>(d_temp_storage, temp_storage_bytes, d_in, d_argmin, num_items);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Allocate temporary storage</span></div>
<div class="line">cudaMalloc(&amp;d_temp_storage, temp_storage_bytes);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Run argmin-reduction</span></div>
<div class="line"><a class="code" href="structcub_1_1_device_reduce.html#af3dc1b284c8828d1e51da587a090a140" title="Finds the first device-wide minimum using the less-than (&#39;&lt;&#39;) operator, also returning the index o...">cub::DeviceReduce::ArgMin</a>(d_temp_storage, temp_storage_bytes, d_in, d_argmin, num_items);</div>
<div class="line"></div>
<div class="line"><span class="comment">// d_out &lt;-- [{0, 5}]</span></div>
</div><!-- fragment --></dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> Random-access input iterator type for reading input items (of some type <code>T</code>) (may be a simple pointer type) </td></tr>
    <tr><td class="paramname">OutputIterator</td><td><b>[inferred]</b> Output iterator type for recording the reduced aggregate (having value type <code>ItemOffsetPair&lt;T, int&gt;</code>) (may be a simple pointer type) </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">d_temp_storage</td><td>Device allocation of temporary storage. When NULL, the required allocation size is written to <code>temp_storage_bytes</code> and no work is done. </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">temp_storage_bytes</td><td>Reference to size in bytes of <code>d_temp_storage</code> allocation </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">d_in</td><td>Pointer to the input sequence of data items </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">d_out</td><td>Pointer to the output aggregate </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_items</td><td>Total number of input items (i.e., length of <code>d_in</code>) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stream</td><td><b>[optional]</b> CUDA stream to launch kernels within. Default is stream<sub>0</sub>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">debug_synchronous</td><td><b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors. Also causes launch configurations to be printed to the console. Default is <code>false</code>. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="device__reduce_8cuh_source.html#l00375">375</a> of file <a class="el" href="device__reduce_8cuh_source.html">device_reduce.cuh</a>.</p>

</div>
</div>
<a class="anchor" id="a335a77d51f436c8840b50f53cab137a5"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename InputIterator , typename OutputIterator &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">__host__ static __device__ cudaError_t cub::DeviceReduce::Max </td>
          <td>(</td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>d_temp_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t &amp;&#160;</td>
          <td class="paramname"><em>temp_storage_bytes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>d_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">OutputIterator&#160;</td>
          <td class="paramname"><em>d_out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>debug_synchronous</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Computes a device-wide maximum using the greater-than ('&gt;') operator. </p>
<dl class="section user"><dt></dt><dd><ul>
<li>Does not support non-commutative maximum operators.</li>
<li>This operation requires an allocation of temporary device storage. When <code>d_temp_storage</code> is NULL, no work is done and the required allocation size is returned in <code>temp_storage_bytes</code>.</li>
<li>When calling this method from kernel code, be sure to define the <code>CUB_CDP</code> macro in your compiler's macro definitions.</li>
</ul>
</dd></dl>
<dl class="section user"><dt>Performance</dt><dd>Performance is typically similar to <a class="el" href="structcub_1_1_device_reduce.html#ae38bbfec0b058564ee966c9451fabbcc" title="Computes a device-wide sum using the addition (&#39;+&#39;) operator. ">DeviceReduce::Sum</a>.</dd></dl>
<dl class="section user"><dt>Snippet</dt><dd>The code snippet below illustrates the max-reduction of a device vector of <code>int</code> items. </dd></dl>
<dl class="section user"><dt></dt><dd><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="cub_8cuh.html">cub/cub.cuh</a>&gt;</span>   <span class="comment">// or equivalently &lt;cub/device/device_radix_sort.cuh&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// Declare, allocate, and initialize device pointers for input and output</span></div>
<div class="line"><span class="keywordtype">int</span>  num_items;      <span class="comment">// e.g., 7</span></div>
<div class="line"><span class="keywordtype">int</span>  *d_in;          <span class="comment">// e.g., [8, 6, 7, 5, 3, 0, 9]</span></div>
<div class="line"><span class="keywordtype">int</span>  *d_out;         <span class="comment">// e.g., [ ]</span></div>
<div class="line">...</div>
<div class="line"></div>
<div class="line"><span class="comment">// Determine temporary device storage requirements</span></div>
<div class="line">void     *d_temp_storage = NULL;</div>
<div class="line"><span class="keywordtype">size_t</span>   temp_storage_bytes = 0;</div>
<div class="line"><a class="code" href="structcub_1_1_device_reduce.html#a335a77d51f436c8840b50f53cab137a5" title="Computes a device-wide maximum using the greater-than (&#39;&gt;&#39;) operator. ">cub::DeviceReduce::Max</a>(d_temp_storage, temp_storage_bytes, d_in, d_max, num_items);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Allocate temporary storage</span></div>
<div class="line">cudaMalloc(&amp;d_temp_storage, temp_storage_bytes);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Run max-reduction</span></div>
<div class="line"><a class="code" href="structcub_1_1_device_reduce.html#a335a77d51f436c8840b50f53cab137a5" title="Computes a device-wide maximum using the greater-than (&#39;&gt;&#39;) operator. ">cub::DeviceReduce::Max</a>(d_temp_storage, temp_storage_bytes, d_in, d_max, num_items);</div>
<div class="line"></div>
<div class="line"><span class="comment">// d_out &lt;-- [9]</span></div>
</div><!-- fragment --></dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> Random-access input iterator type for reading input items (may be a simple pointer type) </td></tr>
    <tr><td class="paramname">OutputIterator</td><td><b>[inferred]</b> Output iterator type for recording the reduced aggregate (may be a simple pointer type) </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">d_temp_storage</td><td>Device allocation of temporary storage. When NULL, the required allocation size is written to <code>temp_storage_bytes</code> and no work is done. </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">temp_storage_bytes</td><td>Reference to size in bytes of <code>d_temp_storage</code> allocation </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">d_in</td><td>Pointer to the input sequence of data items </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">d_out</td><td>Pointer to the output aggregate </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_items</td><td>Total number of input items (i.e., length of <code>d_in</code>) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stream</td><td><b>[optional]</b> CUDA stream to launch kernels within. Default is stream<sub>0</sub>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">debug_synchronous</td><td><b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors. Also causes launch configurations to be printed to the console. Default is <code>false</code>. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="device__reduce_8cuh_source.html#l00451">451</a> of file <a class="el" href="device__reduce_8cuh_source.html">device_reduce.cuh</a>.</p>

</div>
</div>
<a class="anchor" id="a7524b86cae1cb19d7a8899141d8c9908"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename InputIterator , typename OutputIterator &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">__host__ static __device__ cudaError_t cub::DeviceReduce::ArgMax </td>
          <td>(</td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>d_temp_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t &amp;&#160;</td>
          <td class="paramname"><em>temp_storage_bytes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>d_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">OutputIterator&#160;</td>
          <td class="paramname"><em>d_out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>debug_synchronous</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Finds the first device-wide maximum using the greater-than ('&gt;') operator, also returning the index of that item. </p>
<dl class="section user"><dt></dt><dd>Assuming the input <code>d_in</code> has value type <code>T</code>, the output <code>d_out</code> must have value type <code>ItemOffsetPair&lt;T, int&gt;</code>. The maximum value is written to <code>d_out.value</code> and its location in the input array is written to <code>d_out.offset</code>.</dd></dl>
<dl class="section user"><dt></dt><dd><ul>
<li>Does not support non-commutative maximum operators.</li>
<li>This operation requires an allocation of temporary device storage. When <code>d_temp_storage</code> is NULL, no work is done and the required allocation size is returned in <code>temp_storage_bytes</code>.</li>
<li>When calling this method from kernel code, be sure to define the <code>CUB_CDP</code> macro in your compiler's macro definitions.</li>
</ul>
</dd></dl>
<dl class="section user"><dt>Performance</dt><dd>Performance is typically similar to <a class="el" href="structcub_1_1_device_reduce.html#ae38bbfec0b058564ee966c9451fabbcc" title="Computes a device-wide sum using the addition (&#39;+&#39;) operator. ">DeviceReduce::Sum</a>.</dd></dl>
<dl class="section user"><dt>Snippet</dt><dd>The code snippet below illustrates the argmax-reduction of a device vector of <code>int</code> items. </dd></dl>
<dl class="section user"><dt></dt><dd><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="cub_8cuh.html">cub/cub.cuh</a>&gt;</span>   <span class="comment">// or equivalently &lt;cub/device/device_reduce.cuh&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// Declare, allocate, and initialize device pointers for input and output</span></div>
<div class="line"><span class="keywordtype">int</span>                      num_items;      <span class="comment">// e.g., 7</span></div>
<div class="line"><span class="keywordtype">int</span>                      *d_in;          <span class="comment">// e.g., [8, 6, 7, 5, 3, 0, 9]</span></div>
<div class="line">ItemOffsetPair&lt;int, int&gt; *d_out;         <span class="comment">// e.g., [{ , }]</span></div>
<div class="line">...</div>
<div class="line"></div>
<div class="line"><span class="comment">// Determine temporary device storage requirements</span></div>
<div class="line">void     *d_temp_storage = NULL;</div>
<div class="line"><span class="keywordtype">size_t</span>   temp_storage_bytes = 0;</div>
<div class="line"><a class="code" href="structcub_1_1_device_reduce.html#a7524b86cae1cb19d7a8899141d8c9908" title="Finds the first device-wide maximum using the greater-than (&#39;&gt;&#39;) operator, also returning the inde...">cub::DeviceReduce::ArgMax</a>(d_temp_storage, temp_storage_bytes, d_in, d_argmax, num_items);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Allocate temporary storage</span></div>
<div class="line">cudaMalloc(&amp;d_temp_storage, temp_storage_bytes);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Run argmax-reduction</span></div>
<div class="line"><a class="code" href="structcub_1_1_device_reduce.html#a7524b86cae1cb19d7a8899141d8c9908" title="Finds the first device-wide maximum using the greater-than (&#39;&gt;&#39;) operator, also returning the inde...">cub::DeviceReduce::ArgMax</a>(d_temp_storage, temp_storage_bytes, d_in, d_argmax, num_items);</div>
<div class="line"></div>
<div class="line"><span class="comment">// d_out &lt;-- [{9, 6}]</span></div>
</div><!-- fragment --></dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> Random-access input iterator type for reading input items (of some type <code>T</code>) (may be a simple pointer type) </td></tr>
    <tr><td class="paramname">OutputIterator</td><td><b>[inferred]</b> Output iterator type for recording the reduced aggregate (having value type <code>ItemOffsetPair&lt;T, int&gt;</code>) (may be a simple pointer type) </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">d_temp_storage</td><td>Device allocation of temporary storage. When NULL, the required allocation size is written to <code>temp_storage_bytes</code> and no work is done. </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">temp_storage_bytes</td><td>Reference to size in bytes of <code>d_temp_storage</code> allocation </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">d_in</td><td>Pointer to the input sequence of data items </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">d_out</td><td>Pointer to the output aggregate </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_items</td><td>Total number of input items (i.e., length of <code>d_in</code>) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stream</td><td><b>[optional]</b> CUDA stream to launch kernels within. Default is stream<sub>0</sub>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">debug_synchronous</td><td><b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors. Also causes launch configurations to be printed to the console. Default is <code>false</code>. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="device__reduce_8cuh_source.html#l00528">528</a> of file <a class="el" href="device__reduce_8cuh_source.html">device_reduce.cuh</a>.</p>

</div>
</div>
<a class="anchor" id="a62400e8632002f3ba601d4392b997bc7"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename KeyInputIterator , typename KeyOutputIterator , typename ValueInputIterator , typename ValueOutputIterator , typename NumSegmentsIterator , typename ReductionOp &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">__host__ __device__ static __forceinline__ cudaError_t cub::DeviceReduce::ReduceByKey </td>
          <td>(</td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>d_temp_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t &amp;&#160;</td>
          <td class="paramname"><em>temp_storage_bytes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">KeyInputIterator&#160;</td>
          <td class="paramname"><em>d_keys_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">KeyOutputIterator&#160;</td>
          <td class="paramname"><em>d_keys_out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ValueInputIterator&#160;</td>
          <td class="paramname"><em>d_values_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ValueOutputIterator&#160;</td>
          <td class="paramname"><em>d_values_out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NumSegmentsIterator&#160;</td>
          <td class="paramname"><em>d_num_segments</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ReductionOp&#160;</td>
          <td class="paramname"><em>reduction_op</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>debug_synchronous</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Reduces segments of values, where segments are demarcated by corresponding runs of identical keys. </p>
<dl class="section user"><dt></dt><dd>This operation computes segmented reductions using the specified binary <code>reduction_op</code> functor. Each "run" of consecutive, identical keys in <code>d_keys_in</code> is used to identify a corresponding segment of values in <code>d_values_in</code>. The first key in the <em>i</em><sup>th</sup> segment is copied to <code>d_keys_out[<em>i</em>]</code>, and the value aggregate for that segment is written to <code>d_values_out[<em>i</em>]</code>. The total number of segments discovered is written to <code>d_num_segments</code>.</dd></dl>
<dl class="section user"><dt></dt><dd><ul>
<li>The <code>==</code> equality operator is used to determine whether keys are equivalent</li>
<li>This operation requires an allocation of temporary device storage. When <code>d_temp_storage</code> is NULL, no work is done and the required allocation size is returned in <code>temp_storage_bytes</code>.</li>
<li>When calling this method from kernel code, be sure to define the <code>CUB_CDP</code> macro in your compiler's macro definitions.</li>
</ul>
</dd></dl>
<dl class="section user"><dt>Performance</dt><dd>The following chart illustrates reduction-by-key (sum) performance across different CUDA architectures for <code>fp32</code> and <code>fp64</code> values, respectively. Segments are identified by <code>int32</code> keys, and have lengths uniformly sampled from [1,1000].</dd></dl>
<div class="image">
<img src="reduce_by_key_fp32_len_500.png" alt="reduce_by_key_fp32_len_500.png"/>
</div>
 <div class="image">
<img src="reduce_by_key_fp64_len_500.png" alt="reduce_by_key_fp64_len_500.png"/>
</div>
<dl class="section user"><dt></dt><dd>The following charts are similar, but with segment lengths uniformly sampled from [1,10]:</dd></dl>
<div class="image">
<img src="reduce_by_key_fp32_len_5.png" alt="reduce_by_key_fp32_len_5.png"/>
</div>
 <div class="image">
<img src="reduce_by_key_fp64_len_5.png" alt="reduce_by_key_fp64_len_5.png"/>
</div>
<dl class="section user"><dt>Snippet</dt><dd>The code snippet below illustrates the segmented reduction of <code>int</code> values grouped by runs of associated <code>int</code> keys. </dd></dl>
<dl class="section user"><dt></dt><dd><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="cub_8cuh.html">cub/cub.cuh</a>&gt;</span>   <span class="comment">// or equivalently &lt;cub/device/device_reduce.cuh&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// CustomMin functor</span></div>
<div class="line"><span class="keyword">struct </span>CustomMin</div>
<div class="line">{</div>
<div class="line">    <span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div>
<div class="line">    __host__ __device__ __forceinline__</div>
<div class="line">    T operator()(<span class="keyword">const</span> T &amp;a, <span class="keyword">const</span> T &amp;b)<span class="keyword"> const </span>{</div>
<div class="line">        <span class="keywordflow">return</span> (b &lt; a) ? b : a;</div>
<div class="line">    }</div>
<div class="line">};</div>
<div class="line"></div>
<div class="line"><span class="comment">// Declare, allocate, and initialize device pointers for input and output</span></div>
<div class="line"><span class="keywordtype">int</span>          num_items;          <span class="comment">// e.g., 8</span></div>
<div class="line"><span class="keywordtype">int</span>          *d_keys_in;         <span class="comment">// e.g., [0, 2, 2, 9, 5, 5, 5, 8]</span></div>
<div class="line"><span class="keywordtype">int</span>          *d_values_in;       <span class="comment">// e.g., [0, 7, 1, 6, 2, 5, 3, 4]</span></div>
<div class="line"><span class="keywordtype">int</span>          *d_keys_out;        <span class="comment">// e.g., [ ,  ,  ,  ,  ,  ,  ,  ]</span></div>
<div class="line"><span class="keywordtype">int</span>          *d_values_out;      <span class="comment">// e.g., [ ,  ,  ,  ,  ,  ,  ,  ]</span></div>
<div class="line"><span class="keywordtype">int</span>          *d_num_segments;    <span class="comment">// e.g., [ ]</span></div>
<div class="line">CustomMin    reduction_op;</div>
<div class="line">...</div>
<div class="line"></div>
<div class="line"><span class="comment">// Determine temporary device storage requirements</span></div>
<div class="line">void     *d_temp_storage = NULL;</div>
<div class="line"><span class="keywordtype">size_t</span>   temp_storage_bytes = 0;</div>
<div class="line">cub::DeviceSelect::ReduceByKey(d_temp_storage, temp_storage_bytes, d_keys_in, d_keys_out, d_values_in, d_values_out, d_num_segments, reduction_op, num_items);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Allocate temporary storage</span></div>
<div class="line">cudaMalloc(&amp;d_temp_storage, temp_storage_bytes);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Run reduce-by-key</span></div>
<div class="line">cub::DeviceSelect::ReduceByKey(d_temp_storage, temp_storage_bytes, d_keys_in, d_keys_out, d_values_in, d_values_out, d_num_segments, reduction_op, num_items);</div>
<div class="line"></div>
<div class="line"><span class="comment">// d_keys_out        &lt;-- [0, 2, 9, 5, 8]</span></div>
<div class="line"><span class="comment">// d_values_out      &lt;-- [0, 1, 6, 2, 4]</span></div>
<div class="line"><span class="comment">// d_num_segments    &lt;-- [5]</span></div>
</div><!-- fragment --></dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">KeyInputIterator</td><td><b>[inferred]</b> Random-access input iterator type for reading input keys (may be a simple pointer type) </td></tr>
    <tr><td class="paramname">KeyOutputIterator</td><td><b>[inferred]</b> Random-access output iterator type for writing output keys (may be a simple pointer type) </td></tr>
    <tr><td class="paramname">ValueInputIterator</td><td><b>[inferred]</b> Random-access input iterator type for reading input values (may be a simple pointer type) </td></tr>
    <tr><td class="paramname">ValueOutputIterator</td><td><b>[inferred]</b> Random-access output iterator type for writing output values (may be a simple pointer type) </td></tr>
    <tr><td class="paramname">NumSegmentsIterator</td><td><b>[inferred]</b> Output iterator type for recording the number of segments encountered (may be a simple pointer type) </td></tr>
    <tr><td class="paramname">ReductionOp</td><td><b>[inferred]</b> Binary reduction functor type having member <code>T operator()(const T &amp;a, const T &amp;b)</code> </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">d_temp_storage</td><td>Device allocation of temporary storage. When NULL, the required allocation size is written to <code>temp_storage_bytes</code> and no work is done. </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">temp_storage_bytes</td><td>Reference to size in bytes of <code>d_temp_storage</code> allocation </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">d_keys_in</td><td>Pointer to consecutive runs of input keys </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">d_keys_out</td><td>Pointer to output keys (one key per run) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">d_values_in</td><td>Pointer to consecutive runs of input values </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">d_values_out</td><td>Pointer to output value aggregates (one aggregate per run) </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">d_num_segments</td><td>Pointer to total number of segments </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">reduction_op</td><td>Binary reduction functor (e.g., an instance of <a class="el" href="structcub_1_1_sum.html" title="Default sum functor. ">cub::Sum</a>, <a class="el" href="structcub_1_1_min.html" title="Default min functor. ">cub::Min</a>, <a class="el" href="structcub_1_1_max.html" title="Default max functor. ">cub::Max</a>, etc.) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_items</td><td>Total number of associated key+value pairs (i.e., the length of <code>d_in_keys</code> and <code>d_in_values</code>) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stream</td><td><b>[optional]</b> CUDA stream to launch kernels within. Default is stream<sub>0</sub>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">debug_synchronous</td><td><b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors. May cause significant slowdown. Default is <code>false</code>. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="device__reduce_8cuh_source.html#l00648">648</a> of file <a class="el" href="device__reduce_8cuh_source.html">device_reduce.cuh</a>.</p>

</div>
</div>
<a class="anchor" id="ac563c98fb1d6cde7d4365bc34f6b698d"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename InputIterator , typename OutputIterator , typename CountsOutputIterator , typename NumSegmentsIterator &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">__host__ __device__ static __forceinline__ cudaError_t cub::DeviceReduce::RunLengthEncode </td>
          <td>(</td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>d_temp_storage</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t &amp;&#160;</td>
          <td class="paramname"><em>temp_storage_bytes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>d_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">OutputIterator&#160;</td>
          <td class="paramname"><em>d_compacted_out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">CountsOutputIterator&#160;</td>
          <td class="paramname"><em>d_counts_out</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">NumSegmentsIterator&#160;</td>
          <td class="paramname"><em>d_num_segments</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>num_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">cudaStream_t&#160;</td>
          <td class="paramname"><em>stream</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>debug_synchronous</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Counts the segment lengths in the sequence <code>d_in</code>, where segments are demarcated by runs of identical values. </p>
<dl class="section user"><dt></dt><dd>This operation computes a run-length encoding of <code>d_in</code>, where segments are identified by "runs" of consecutive, identical values. The length of the <em>i</em><sup>th</sup> segment is written to <code>d_counts_out[<em>i</em>]</code>. The unique values are also compacted, i.e., the first value in the <em>i</em><sup>th</sup> segment is copied to <code>d_compacted_out[<em>i</em>]</code>. The total number of segments discovered is written to <code>d_num_segments</code>.</dd></dl>
<dl class="section user"><dt></dt><dd><ul>
<li>The <code>==</code> equality operator is used to determine whether values are equivalent</li>
<li>This operation requires an allocation of temporary device storage. When <code>d_temp_storage</code> is NULL, no work is done and the required allocation size is returned in <code>temp_storage_bytes</code>.</li>
<li>When calling this method from kernel code, be sure to define the <code>CUB_CDP</code> macro in your compiler's macro definitions.</li>
</ul>
</dd></dl>
<dl class="section user"><dt>Performance</dt><dd>The following charts illustrate saturated encode performance across different CUDA architectures for <code>int32</code> and <code>int64</code> items, respectively. Segments have lengths uniformly sampled from [1,1000].</dd></dl>
<div class="image">
<img src="rle_int32_len_500.png" alt="rle_int32_len_500.png"/>
</div>
 <div class="image">
<img src="rle_int64_len_500.png" alt="rle_int64_len_500.png"/>
</div>
<dl class="section user"><dt></dt><dd>The following charts are similar, but with segment lengths uniformly sampled from [1,10]:</dd></dl>
<div class="image">
<img src="rle_int32_len_5.png" alt="rle_int32_len_5.png"/>
</div>
 <div class="image">
<img src="rle_int64_len_5.png" alt="rle_int64_len_5.png"/>
</div>
<dl class="section user"><dt>Snippet</dt><dd>The code snippet below illustrates the run-length encoding of a sequence of <code>int</code> values. </dd></dl>
<dl class="section user"><dt></dt><dd><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="cub_8cuh.html">cub/cub.cuh</a>&gt;</span>   <span class="comment">// or equivalently &lt;cub/device/device_reduce.cuh&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// Declare, allocate, and initialize device pointers for input and output</span></div>
<div class="line"><span class="keywordtype">int</span>          num_items;          <span class="comment">// e.g., 8</span></div>
<div class="line"><span class="keywordtype">int</span>          *d_in;              <span class="comment">// e.g., [0, 2, 2, 9, 5, 5, 5, 8]</span></div>
<div class="line"><span class="keywordtype">int</span>          *d_compacted_out;   <span class="comment">// e.g., [ ,  ,  ,  ,  ,  ,  ,  ]</span></div>
<div class="line"><span class="keywordtype">int</span>          *d_counts_out;      <span class="comment">// e.g., [ ,  ,  ,  ,  ,  ,  ,  ]</span></div>
<div class="line"><span class="keywordtype">int</span>          *d_num_segments;    <span class="comment">// e.g., [ ]</span></div>
<div class="line">...</div>
<div class="line"></div>
<div class="line"><span class="comment">// Determine temporary device storage requirements</span></div>
<div class="line">void     *d_temp_storage = NULL;</div>
<div class="line"><span class="keywordtype">size_t</span>   temp_storage_bytes = 0;</div>
<div class="line">cub::DeviceSelect::RunLengthEncode(d_temp_storage, temp_storage_bytes, d_in, d_compacted_out, d_counts_out, d_num_segments, num_items);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Allocate temporary storage</span></div>
<div class="line">cudaMalloc(&amp;d_temp_storage, temp_storage_bytes);</div>
<div class="line"></div>
<div class="line"><span class="comment">// Run encoding</span></div>
<div class="line">cub::DeviceSelect::RunLengthEncode(d_temp_storage, temp_storage_bytes, d_in, d_compacted_out, d_counts_out, d_num_segments, num_items);</div>
<div class="line"></div>
<div class="line"><span class="comment">// d_keys_out        &lt;-- [0, 2, 9, 5, 8]</span></div>
<div class="line"><span class="comment">// d_values_out      &lt;-- [1, 2, 1, 3, 1]</span></div>
<div class="line"><span class="comment">// d_num_segments    &lt;-- [5]</span></div>
</div><!-- fragment --></dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> Random-access input iterator type for reading input items (may be a simple pointer type) </td></tr>
    <tr><td class="paramname">OutputIterator</td><td><b>[inferred]</b> Random-access output iterator type for writing compacted output items (may be a simple pointer type) </td></tr>
    <tr><td class="paramname">CountsOutputIterator</td><td><b>[inferred]</b> Random-access output iterator type for writing output counts (may be a simple pointer type) </td></tr>
    <tr><td class="paramname">NumSegmentsIterator</td><td><b>[inferred]</b> Output iterator type for recording the number of segments encountered (may be a simple pointer type) </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">d_temp_storage</td><td>Device allocation of temporary storage. When NULL, the required allocation size is written to <code>temp_storage_bytes</code> and no work is done. </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">temp_storage_bytes</td><td>Reference to size in bytes of <code>d_temp_storage</code> allocation </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">d_in</td><td>Pointer to consecutive runs of input keys </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">d_compacted_out</td><td>Pointer to output keys (one key per run) </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">d_counts_out</td><td>Pointer to output value aggregates (one aggregate per run) </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">d_num_segments</td><td>Pointer to total number of segments </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_items</td><td>Total number of associated key+value pairs (i.e., the length of <code>d_in_keys</code> and <code>d_in_values</code>) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stream</td><td><b>[optional]</b> CUDA stream to launch kernels within. Default is stream<sub>0</sub>. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">debug_synchronous</td><td><b>[optional]</b> Whether or not to synchronize the stream after every kernel launch to check for errors. May cause significant slowdown. Default is <code>false</code>. </td></tr>
  </table>
  </dd>
</dl>

<p>Definition at line <a class="el" href="device__reduce_8cuh_source.html#l00754">754</a> of file <a class="el" href="device__reduce_8cuh_source.html">device_reduce.cuh</a>.</p>

</div>
</div>
<hr/>The documentation for this struct was generated from the following file:<ul>
<li><a class="el" href="device__reduce_8cuh_source.html">device_reduce.cuh</a></li>
</ul>
</div><!-- contents -->
<!-- HTML footer for doxygen 1.8.3.1-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Tue Apr 1 2014 16:19:43 for CUB by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.4
<br>
&copy; 2013 NVIDIA Corporation
</small></address>
</body>
</html>
