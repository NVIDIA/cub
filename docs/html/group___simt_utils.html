<!-- HTML header for doxygen 1.8.3.1-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.3.1"/>
<title>CUB: SIMT Utilities</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="extra_stylesheet.css" rel="stylesheet" type="text/css"/>
<link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-38890655-1']);
  _gaq.push(['_trackPageview']);
  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">CUB
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.3.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Macros</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(10)"><span class="SelectionMark">&#160;</span>Groups</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(11)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#enum-members">Enumerations</a>  </div>
  <div class="headertitle">
<div class="title">SIMT Utilities<div class="ingroups"><a class="el" href="group___simt.html">SIMT Primitives</a></div></div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcub_1_1_equality.html">cub::Equality&lt; T &gt;</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Default equality functor.  <a href="structcub_1_1_equality.html#details">More...</a><br/></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcub_1_1_max.html">cub::Max&lt; T &gt;</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Default max functor.  <a href="structcub_1_1_max.html#details">More...</a><br/></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structcub_1_1_sum.html">cub::Sum&lt; T &gt;</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Default sum functor.  <a href="structcub_1_1_sum.html#details">More...</a><br/></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="enum-members"></a>
Enumerations</h2></td></tr>
<tr class="memitem:ga023420f30fec7d4b187fc98f4fd2a55d"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#ga023420f30fec7d4b187fc98f4fd2a55d">cub::PtxLoadModifier</a> { <br/>
&#160;&#160;<a class="el" href="group___simt_utils.html#gga023420f30fec7d4b187fc98f4fd2a55da017db24b99abd332be14151d35fa3cf5">cub::PTX_LOAD_NONE</a>, 
<a class="el" href="group___simt_utils.html#gga023420f30fec7d4b187fc98f4fd2a55dad802bce71c7380a911ab0cee5b366fd3">cub::PTX_LOAD_CA</a>, 
<a class="el" href="group___simt_utils.html#gga023420f30fec7d4b187fc98f4fd2a55da0e18a5a910be460d738772631eafadd0">cub::PTX_LOAD_CG</a>, 
<a class="el" href="group___simt_utils.html#gga023420f30fec7d4b187fc98f4fd2a55da0b263e2237593103d5e9004e935c66af">cub::PTX_LOAD_CS</a>, 
<br/>
&#160;&#160;<a class="el" href="group___simt_utils.html#gga023420f30fec7d4b187fc98f4fd2a55da05ee1b160fa298ef4b2578a9df1c1350">cub::PTX_LOAD_CV</a>, 
<a class="el" href="group___simt_utils.html#gga023420f30fec7d4b187fc98f4fd2a55dae8ca2d6545712389c0578224f214913d">cub::PTX_LOAD_LDG</a>, 
<a class="el" href="group___simt_utils.html#gga023420f30fec7d4b187fc98f4fd2a55dae4cbe986a2413b418ec83e8bb153b990">cub::PTX_LOAD_VS</a>
<br/>
 }</td></tr>
<tr class="memdesc:ga023420f30fec7d4b187fc98f4fd2a55d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Enumeration of PTX cache-modifiers for memory load operations.  <a href="group___simt_utils.html#ga023420f30fec7d4b187fc98f4fd2a55d">More...</a><br/></td></tr>
<tr class="separator:ga023420f30fec7d4b187fc98f4fd2a55d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae9c7d6a6af7104f528509182ac9c9da2"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#gae9c7d6a6af7104f528509182ac9c9da2">cub::PtxStoreModifier</a> { <br/>
&#160;&#160;<a class="el" href="group___simt_utils.html#ggae9c7d6a6af7104f528509182ac9c9da2a5437dabe5d300b7188dbb42132363c05">cub::PTX_STORE_NONE</a>, 
<a class="el" href="group___simt_utils.html#ggae9c7d6a6af7104f528509182ac9c9da2a2d57d44c3dbebbae63abcc3ccb80a412">cub::PTX_STORE_WB</a>, 
<a class="el" href="group___simt_utils.html#ggae9c7d6a6af7104f528509182ac9c9da2a95a2bc222f2adce9dd2d0251f53e1d91">cub::PTX_STORE_CG</a>, 
<a class="el" href="group___simt_utils.html#ggae9c7d6a6af7104f528509182ac9c9da2ac08bd33e1c4694ccdb899dd9bdef9c96">cub::PTX_STORE_CS</a>, 
<br/>
&#160;&#160;<a class="el" href="group___simt_utils.html#ggae9c7d6a6af7104f528509182ac9c9da2a8d07fc5099d72afdc46b817d566d3df8">cub::PTX_STORE_WT</a>, 
<a class="el" href="group___simt_utils.html#ggae9c7d6a6af7104f528509182ac9c9da2adee47f52a9358d88446393c5affd11aa">cub::PTX_STORE_VS</a>
<br/>
 }</td></tr>
<tr class="memdesc:gae9c7d6a6af7104f528509182ac9c9da2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Enumeration of PTX cache-modifiers for memory store operations.  <a href="group___simt_utils.html#gae9c7d6a6af7104f528509182ac9c9da2">More...</a><br/></td></tr>
<tr class="separator:gae9c7d6a6af7104f528509182ac9c9da2"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="member-group"></a>
Direct threadblock loads (blocked arrangement)</h2></td></tr>
<tr class="memitem:ga2ece00cc00c1d3269ee79ddf60d15457"><td class="memTemplParams" colspan="2">template&lt;PtxLoadModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename InputIterator &gt; </td></tr>
<tr class="memitem:ga2ece00cc00c1d3269ee79ddf60d15457"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#ga2ece00cc00c1d3269ee79ddf60d15457">cub::BlockLoadDirect</a> (InputIterator block_itr, T(&amp;items)[ITEMS_PER_THREAD])</td></tr>
<tr class="memdesc:ga2ece00cc00c1d3269ee79ddf60d15457"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load a tile of items across a threadblock directly using the specified cache modifier.  <a href="#ga2ece00cc00c1d3269ee79ddf60d15457">More...</a><br/></td></tr>
<tr class="separator:ga2ece00cc00c1d3269ee79ddf60d15457"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga51495fa39938ecf57056d4ca6f0260de"><td class="memTemplParams" colspan="2">template&lt;typename T , int ITEMS_PER_THREAD, typename InputIterator &gt; </td></tr>
<tr class="memitem:ga51495fa39938ecf57056d4ca6f0260de"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#ga51495fa39938ecf57056d4ca6f0260de">cub::BlockLoadDirect</a> (InputIterator block_itr, T(&amp;items)[ITEMS_PER_THREAD])</td></tr>
<tr class="memdesc:ga51495fa39938ecf57056d4ca6f0260de"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load a tile of items across a threadblock directly.  <a href="#ga51495fa39938ecf57056d4ca6f0260de">More...</a><br/></td></tr>
<tr class="separator:ga51495fa39938ecf57056d4ca6f0260de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga01e0a2d42d5b20aab660815c5cf258a0"><td class="memTemplParams" colspan="2">template&lt;PtxLoadModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename InputIterator , typename SizeT &gt; </td></tr>
<tr class="memitem:ga01e0a2d42d5b20aab660815c5cf258a0"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#ga01e0a2d42d5b20aab660815c5cf258a0">cub::BlockLoadDirect</a> (InputIterator block_itr, const SizeT &amp;guarded_items, T(&amp;items)[ITEMS_PER_THREAD])</td></tr>
<tr class="memdesc:ga01e0a2d42d5b20aab660815c5cf258a0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load a tile of items across a threadblock directly using the specified cache modifier, guarded by range.  <a href="#ga01e0a2d42d5b20aab660815c5cf258a0">More...</a><br/></td></tr>
<tr class="separator:ga01e0a2d42d5b20aab660815c5cf258a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaac537b6a8c9caaae1e6e77e9717e9541"><td class="memTemplParams" colspan="2">template&lt;typename T , int ITEMS_PER_THREAD, typename InputIterator , typename SizeT &gt; </td></tr>
<tr class="memitem:gaac537b6a8c9caaae1e6e77e9717e9541"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#gaac537b6a8c9caaae1e6e77e9717e9541">cub::BlockLoadDirect</a> (InputIterator block_itr, const SizeT &amp;guarded_items, T(&amp;items)[ITEMS_PER_THREAD])</td></tr>
<tr class="memdesc:gaac537b6a8c9caaae1e6e77e9717e9541"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load a tile of items across a threadblock directly, guarded by range.  <a href="#gaac537b6a8c9caaae1e6e77e9717e9541">More...</a><br/></td></tr>
<tr class="separator:gaac537b6a8c9caaae1e6e77e9717e9541"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae910789e82acd344d6f5a4cc50beef03"><td class="memTemplParams" colspan="2">template&lt;PtxLoadModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename InputIterator , typename SizeT &gt; </td></tr>
<tr class="memitem:gae910789e82acd344d6f5a4cc50beef03"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#gae910789e82acd344d6f5a4cc50beef03">cub::BlockLoadDirect</a> (InputIterator block_itr, const SizeT &amp;guarded_items, T oob_default, T(&amp;items)[ITEMS_PER_THREAD])</td></tr>
<tr class="memdesc:gae910789e82acd344d6f5a4cc50beef03"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load a tile of items across a threadblock directly using the specified cache modifier, guarded by range, with assignment for out-of-bound elements.  <a href="#gae910789e82acd344d6f5a4cc50beef03">More...</a><br/></td></tr>
<tr class="separator:gae910789e82acd344d6f5a4cc50beef03"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gac20fbd7aaa120e661575fe6e8028a015"><td class="memTemplParams" colspan="2">template&lt;typename T , int ITEMS_PER_THREAD, typename InputIterator , typename SizeT &gt; </td></tr>
<tr class="memitem:gac20fbd7aaa120e661575fe6e8028a015"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#gac20fbd7aaa120e661575fe6e8028a015">cub::BlockLoadDirect</a> (InputIterator block_itr, const SizeT &amp;guarded_items, T oob_default, T(&amp;items)[ITEMS_PER_THREAD])</td></tr>
<tr class="memdesc:gac20fbd7aaa120e661575fe6e8028a015"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load a tile of items across a threadblock directly, guarded by range, with assignment for out-of-bound elements.  <a href="#gac20fbd7aaa120e661575fe6e8028a015">More...</a><br/></td></tr>
<tr class="separator:gac20fbd7aaa120e661575fe6e8028a015"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="member-group"></a>
Direct threadblock loads (striped arrangement)</h2></td></tr>
<tr class="memitem:ga10442f4a83e49fb4a414ce6ce9234b79"><td class="memTemplParams" colspan="2">template&lt;PtxLoadModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename InputIterator &gt; </td></tr>
<tr class="memitem:ga10442f4a83e49fb4a414ce6ce9234b79"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#ga10442f4a83e49fb4a414ce6ce9234b79">cub::BlockLoadDirectStriped</a> (InputIterator block_itr, T(&amp;items)[ITEMS_PER_THREAD], int stride=blockDim.x)</td></tr>
<tr class="memdesc:ga10442f4a83e49fb4a414ce6ce9234b79"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load striped tile directly using the specified cache modifier.  <a href="#ga10442f4a83e49fb4a414ce6ce9234b79">More...</a><br/></td></tr>
<tr class="separator:ga10442f4a83e49fb4a414ce6ce9234b79"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga74f3768367f80c79037b3e77c13bf4bc"><td class="memTemplParams" colspan="2">template&lt;typename T , int ITEMS_PER_THREAD, typename InputIterator &gt; </td></tr>
<tr class="memitem:ga74f3768367f80c79037b3e77c13bf4bc"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#ga74f3768367f80c79037b3e77c13bf4bc">cub::BlockLoadDirectStriped</a> (InputIterator block_itr, T(&amp;items)[ITEMS_PER_THREAD], int stride=blockDim.x)</td></tr>
<tr class="memdesc:ga74f3768367f80c79037b3e77c13bf4bc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load striped tile directly.  <a href="#ga74f3768367f80c79037b3e77c13bf4bc">More...</a><br/></td></tr>
<tr class="separator:ga74f3768367f80c79037b3e77c13bf4bc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga405e4ed36717a6d2c0584578ab94923a"><td class="memTemplParams" colspan="2">template&lt;PtxLoadModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename InputIterator , typename SizeT &gt; </td></tr>
<tr class="memitem:ga405e4ed36717a6d2c0584578ab94923a"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#ga405e4ed36717a6d2c0584578ab94923a">cub::BlockLoadDirectStriped</a> (InputIterator block_itr, const SizeT &amp;guarded_items, T(&amp;items)[ITEMS_PER_THREAD], int stride=blockDim.x)</td></tr>
<tr class="memdesc:ga405e4ed36717a6d2c0584578ab94923a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load striped directly tile using the specified cache modifier, guarded by range.  <a href="#ga405e4ed36717a6d2c0584578ab94923a">More...</a><br/></td></tr>
<tr class="separator:ga405e4ed36717a6d2c0584578ab94923a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga7ba15be704f5aa7c7db809a66af43160"><td class="memTemplParams" colspan="2">template&lt;typename T , int ITEMS_PER_THREAD, typename InputIterator , typename SizeT &gt; </td></tr>
<tr class="memitem:ga7ba15be704f5aa7c7db809a66af43160"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#ga7ba15be704f5aa7c7db809a66af43160">cub::BlockLoadDirectStriped</a> (InputIterator block_itr, const SizeT &amp;guarded_items, T(&amp;items)[ITEMS_PER_THREAD], int stride=blockDim.x)</td></tr>
<tr class="memdesc:ga7ba15be704f5aa7c7db809a66af43160"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load striped tile directly, guarded by range.  <a href="#ga7ba15be704f5aa7c7db809a66af43160">More...</a><br/></td></tr>
<tr class="separator:ga7ba15be704f5aa7c7db809a66af43160"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gabf20f04ee43adc4661429a7902f71911"><td class="memTemplParams" colspan="2">template&lt;PtxLoadModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename InputIterator , typename SizeT &gt; </td></tr>
<tr class="memitem:gabf20f04ee43adc4661429a7902f71911"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#gabf20f04ee43adc4661429a7902f71911">cub::BlockLoadDirectStriped</a> (InputIterator block_itr, const SizeT &amp;guarded_items, T oob_default, T(&amp;items)[ITEMS_PER_THREAD], int stride=blockDim.x)</td></tr>
<tr class="memdesc:gabf20f04ee43adc4661429a7902f71911"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load striped directly tile using the specified cache modifier, guarded by range, with assignment for out-of-bound elements.  <a href="#gabf20f04ee43adc4661429a7902f71911">More...</a><br/></td></tr>
<tr class="separator:gabf20f04ee43adc4661429a7902f71911"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf826ded39a7e107a5f15416d4b147be0"><td class="memTemplParams" colspan="2">template&lt;typename T , int ITEMS_PER_THREAD, typename InputIterator , typename SizeT &gt; </td></tr>
<tr class="memitem:gaf826ded39a7e107a5f15416d4b147be0"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#gaf826ded39a7e107a5f15416d4b147be0">cub::BlockLoadDirectStriped</a> (InputIterator block_itr, const SizeT &amp;guarded_items, T oob_default, T(&amp;items)[ITEMS_PER_THREAD], int stride=blockDim.x)</td></tr>
<tr class="memdesc:gaf826ded39a7e107a5f15416d4b147be0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load striped tile directly, guarded by range, with assignment for out-of-bound elements.  <a href="#gaf826ded39a7e107a5f15416d4b147be0">More...</a><br/></td></tr>
<tr class="separator:gaf826ded39a7e107a5f15416d4b147be0"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="member-group"></a>
Threadblock vectorized loads (blocked arrangement)</h2></td></tr>
<tr class="memitem:gaea8200ef976bb588c569e039ea79005c"><td class="memTemplParams" colspan="2">template&lt;PtxLoadModifier MODIFIER, typename T , int ITEMS_PER_THREAD&gt; </td></tr>
<tr class="memitem:gaea8200ef976bb588c569e039ea79005c"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#gaea8200ef976bb588c569e039ea79005c">cub::BlockLoadVectorized</a> (T *block_ptr, T(&amp;items)[ITEMS_PER_THREAD])</td></tr>
<tr class="memdesc:gaea8200ef976bb588c569e039ea79005c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load a tile of items across a threadblock directly using the specified cache modifier.  <a href="#gaea8200ef976bb588c569e039ea79005c">More...</a><br/></td></tr>
<tr class="separator:gaea8200ef976bb588c569e039ea79005c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab1a8ffc7fe70a636a3d09403344cfced"><td class="memTemplParams" colspan="2">template&lt;typename T , int ITEMS_PER_THREAD&gt; </td></tr>
<tr class="memitem:gab1a8ffc7fe70a636a3d09403344cfced"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#gab1a8ffc7fe70a636a3d09403344cfced">cub::BlockLoadVectorized</a> (T *block_ptr, T(&amp;items)[ITEMS_PER_THREAD])</td></tr>
<tr class="memdesc:gab1a8ffc7fe70a636a3d09403344cfced"><td class="mdescLeft">&#160;</td><td class="mdescRight">Load a tile of items across a threadblock directly.  <a href="#gab1a8ffc7fe70a636a3d09403344cfced">More...</a><br/></td></tr>
<tr class="separator:gab1a8ffc7fe70a636a3d09403344cfced"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="member-group"></a>
Direct threadblock stores (blocked arrangement)</h2></td></tr>
<tr class="memitem:gaa8f12f02c082f8d689100b8ac88f8f61"><td class="memTemplParams" colspan="2">template&lt;PtxStoreModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename OutputIterator &gt; </td></tr>
<tr class="memitem:gaa8f12f02c082f8d689100b8ac88f8f61"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#gaa8f12f02c082f8d689100b8ac88f8f61">cub::BlockStoreDirect</a> (OutputIterator block_itr, T(&amp;items)[ITEMS_PER_THREAD])</td></tr>
<tr class="memdesc:gaa8f12f02c082f8d689100b8ac88f8f61"><td class="mdescLeft">&#160;</td><td class="mdescRight">Store a tile of items across a threadblock directly using the specified cache modifier.  <a href="#gaa8f12f02c082f8d689100b8ac88f8f61">More...</a><br/></td></tr>
<tr class="separator:gaa8f12f02c082f8d689100b8ac88f8f61"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2d52e8ce92c8bc044898cc289a7e96b4"><td class="memTemplParams" colspan="2">template&lt;typename T , int ITEMS_PER_THREAD, typename OutputIterator &gt; </td></tr>
<tr class="memitem:ga2d52e8ce92c8bc044898cc289a7e96b4"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#ga2d52e8ce92c8bc044898cc289a7e96b4">cub::BlockStoreDirect</a> (OutputIterator block_itr, T(&amp;items)[ITEMS_PER_THREAD])</td></tr>
<tr class="memdesc:ga2d52e8ce92c8bc044898cc289a7e96b4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Store a tile of items across a threadblock directly.  <a href="#ga2d52e8ce92c8bc044898cc289a7e96b4">More...</a><br/></td></tr>
<tr class="separator:ga2d52e8ce92c8bc044898cc289a7e96b4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8b5f82ad8487072b6cc80b312db1962d"><td class="memTemplParams" colspan="2">template&lt;PtxStoreModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename OutputIterator , typename SizeT &gt; </td></tr>
<tr class="memitem:ga8b5f82ad8487072b6cc80b312db1962d"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#ga8b5f82ad8487072b6cc80b312db1962d">cub::BlockStoreDirect</a> (OutputIterator block_itr, const SizeT &amp;guarded_items, T(&amp;items)[ITEMS_PER_THREAD])</td></tr>
<tr class="memdesc:ga8b5f82ad8487072b6cc80b312db1962d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Store a tile of items across a threadblock directly using the specified cache modifier, guarded by range.  <a href="#ga8b5f82ad8487072b6cc80b312db1962d">More...</a><br/></td></tr>
<tr class="separator:ga8b5f82ad8487072b6cc80b312db1962d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga34a623c83894408f4f05ceb788d5ac92"><td class="memTemplParams" colspan="2">template&lt;typename T , int ITEMS_PER_THREAD, typename OutputIterator , typename SizeT &gt; </td></tr>
<tr class="memitem:ga34a623c83894408f4f05ceb788d5ac92"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#ga34a623c83894408f4f05ceb788d5ac92">cub::BlockStoreDirect</a> (OutputIterator block_itr, const SizeT &amp;guarded_items, T(&amp;items)[ITEMS_PER_THREAD])</td></tr>
<tr class="memdesc:ga34a623c83894408f4f05ceb788d5ac92"><td class="mdescLeft">&#160;</td><td class="mdescRight">Store a tile of items across a threadblock directly, guarded by range.  <a href="#ga34a623c83894408f4f05ceb788d5ac92">More...</a><br/></td></tr>
<tr class="separator:ga34a623c83894408f4f05ceb788d5ac92"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="member-group"></a>
Direct threadblock stores (striped arrangement)</h2></td></tr>
<tr class="memitem:gaa18341f23a5d00c1b148e0013a9cc637"><td class="memTemplParams" colspan="2">template&lt;PtxStoreModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename OutputIterator &gt; </td></tr>
<tr class="memitem:gaa18341f23a5d00c1b148e0013a9cc637"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#gaa18341f23a5d00c1b148e0013a9cc637">cub::BlockStoreDirectStriped</a> (OutputIterator block_itr, T(&amp;items)[ITEMS_PER_THREAD], int stride=blockDim.x)</td></tr>
<tr class="memdesc:gaa18341f23a5d00c1b148e0013a9cc637"><td class="mdescLeft">&#160;</td><td class="mdescRight">Store striped tile directly using the specified cache modifier.  <a href="#gaa18341f23a5d00c1b148e0013a9cc637">More...</a><br/></td></tr>
<tr class="separator:gaa18341f23a5d00c1b148e0013a9cc637"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaed26402e843c84978ce85da24819ebeb"><td class="memTemplParams" colspan="2">template&lt;typename T , int ITEMS_PER_THREAD, typename OutputIterator &gt; </td></tr>
<tr class="memitem:gaed26402e843c84978ce85da24819ebeb"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#gaed26402e843c84978ce85da24819ebeb">cub::BlockStoreDirectStriped</a> (OutputIterator block_itr, T(&amp;items)[ITEMS_PER_THREAD], int stride=blockDim.x)</td></tr>
<tr class="memdesc:gaed26402e843c84978ce85da24819ebeb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Store striped tile directly.  <a href="#gaed26402e843c84978ce85da24819ebeb">More...</a><br/></td></tr>
<tr class="separator:gaed26402e843c84978ce85da24819ebeb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gadcef89bcc6b3c66e1fa1267c15b08a78"><td class="memTemplParams" colspan="2">template&lt;PtxStoreModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename OutputIterator , typename SizeT &gt; </td></tr>
<tr class="memitem:gadcef89bcc6b3c66e1fa1267c15b08a78"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#gadcef89bcc6b3c66e1fa1267c15b08a78">cub::BlockStoreDirectStriped</a> (OutputIterator block_itr, const SizeT &amp;guarded_items, T(&amp;items)[ITEMS_PER_THREAD], int stride=blockDim.x)</td></tr>
<tr class="separator:gadcef89bcc6b3c66e1fa1267c15b08a78"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga75150e5519f86c1054d7a7584e1a4f23"><td class="memTemplParams" colspan="2">template&lt;typename T , int ITEMS_PER_THREAD, typename OutputIterator , typename SizeT &gt; </td></tr>
<tr class="memitem:ga75150e5519f86c1054d7a7584e1a4f23"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#ga75150e5519f86c1054d7a7584e1a4f23">cub::BlockStoreDirectStriped</a> (OutputIterator block_itr, const SizeT &amp;guarded_items, T(&amp;items)[ITEMS_PER_THREAD], int stride=blockDim.x)</td></tr>
<tr class="memdesc:ga75150e5519f86c1054d7a7584e1a4f23"><td class="mdescLeft">&#160;</td><td class="mdescRight">Store striped tile directly, guarded by range.  <a href="#ga75150e5519f86c1054d7a7584e1a4f23">More...</a><br/></td></tr>
<tr class="separator:ga75150e5519f86c1054d7a7584e1a4f23"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="member-group"></a>
Threadblock vectorized stores (blocked arrangement)</h2></td></tr>
<tr class="memitem:ga013c3ab8214854f45e8d678958e7dde9"><td class="memTemplParams" colspan="2">template&lt;PtxStoreModifier MODIFIER, typename T , int ITEMS_PER_THREAD&gt; </td></tr>
<tr class="memitem:ga013c3ab8214854f45e8d678958e7dde9"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#ga013c3ab8214854f45e8d678958e7dde9">cub::BlockStoreVectorized</a> (T *block_ptr, T(&amp;items)[ITEMS_PER_THREAD])</td></tr>
<tr class="memdesc:ga013c3ab8214854f45e8d678958e7dde9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Store a tile of items across a threadblock directly using the specified cache modifier.  <a href="#ga013c3ab8214854f45e8d678958e7dde9">More...</a><br/></td></tr>
<tr class="separator:ga013c3ab8214854f45e8d678958e7dde9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5db0cef20c11ea62aef484c587c4e064"><td class="memTemplParams" colspan="2">template&lt;typename T , int ITEMS_PER_THREAD&gt; </td></tr>
<tr class="memitem:ga5db0cef20c11ea62aef484c587c4e064"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#ga5db0cef20c11ea62aef484c587c4e064">cub::BlockStoreVectorized</a> (T *block_ptr, T(&amp;items)[ITEMS_PER_THREAD])</td></tr>
<tr class="memdesc:ga5db0cef20c11ea62aef484c587c4e064"><td class="mdescLeft">&#160;</td><td class="mdescRight">Store a tile of items across a threadblock directly.  <a href="#ga5db0cef20c11ea62aef484c587c4e064">More...</a><br/></td></tr>
<tr class="separator:ga5db0cef20c11ea62aef484c587c4e064"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="member-group"></a>
Thread utilities for memory I/O using PTX cache modifiers</h2></td></tr>
<tr class="memitem:ga1e390b9fee4c8012a021d49d9b76b1e8"><td class="memTemplParams" colspan="2">template&lt;PtxLoadModifier MODIFIER, typename InputIterator &gt; </td></tr>
<tr class="memitem:ga1e390b9fee4c8012a021d49d9b76b1e8"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ <br class="typebreak"/>
std::iterator_traits<br class="typebreak"/>
&lt; InputIterator &gt;::value_type&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#ga1e390b9fee4c8012a021d49d9b76b1e8">cub::ThreadLoad</a> (InputIterator itr)</td></tr>
<tr class="memdesc:ga1e390b9fee4c8012a021d49d9b76b1e8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Thread utility for reading memory using <a class="el" href="group___simt_utils.html#ga023420f30fec7d4b187fc98f4fd2a55d" title="Enumeration of PTX cache-modifiers for memory load operations.">cub::PtxLoadModifier</a> cache modifiers.  <a href="#ga1e390b9fee4c8012a021d49d9b76b1e8">More...</a><br/></td></tr>
<tr class="separator:ga1e390b9fee4c8012a021d49d9b76b1e8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad117ecb99b9230a032971b0ac08ca6dc"><td class="memTemplParams" colspan="2">template&lt;PtxStoreModifier MODIFIER, typename OutputIterator , typename T &gt; </td></tr>
<tr class="memitem:gad117ecb99b9230a032971b0ac08ca6dc"><td class="memTemplItemLeft" align="right" valign="top">__device__ __forceinline__ void&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="group___simt_utils.html#gad117ecb99b9230a032971b0ac08ca6dc">cub::ThreadStore</a> (OutputIterator itr, const T &amp;val)</td></tr>
<tr class="memdesc:gad117ecb99b9230a032971b0ac08ca6dc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Thread utility for writing memory using <a class="el" href="group___simt_utils.html#gae9c7d6a6af7104f528509182ac9c9da2" title="Enumeration of PTX cache-modifiers for memory store operations.">cub::PtxStoreModifier</a> cache modifiers.  <a href="#gad117ecb99b9230a032971b0ac08ca6dc">More...</a><br/></td></tr>
<tr class="separator:gad117ecb99b9230a032971b0ac08ca6dc"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Enumeration Type Documentation</h2>
<a class="anchor" id="ga023420f30fec7d4b187fc98f4fd2a55d"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group___simt_utils.html#ga023420f30fec7d4b187fc98f4fd2a55d">cub::PtxLoadModifier</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Enumeration of PTX cache-modifiers for memory load operations. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><em><a class="anchor" id="gga023420f30fec7d4b187fc98f4fd2a55da017db24b99abd332be14151d35fa3cf5"></a>PTX_LOAD_NONE</em>&nbsp;</td><td class="fielddoc">
<p>Default (currently <a class="el" href="group___simt_utils.html#gga023420f30fec7d4b187fc98f4fd2a55dad802bce71c7380a911ab0cee5b366fd3" title="Cache at all levels.">cub::PTX_LOAD_CA</a> for global loads, nothing for smem loads) </p>
</td></tr>
<tr><td class="fieldname"><em><a class="anchor" id="gga023420f30fec7d4b187fc98f4fd2a55dad802bce71c7380a911ab0cee5b366fd3"></a>PTX_LOAD_CA</em>&nbsp;</td><td class="fielddoc">
<p>Cache at all levels. </p>
</td></tr>
<tr><td class="fieldname"><em><a class="anchor" id="gga023420f30fec7d4b187fc98f4fd2a55da0e18a5a910be460d738772631eafadd0"></a>PTX_LOAD_CG</em>&nbsp;</td><td class="fielddoc">
<p>Cache at global level. </p>
</td></tr>
<tr><td class="fieldname"><em><a class="anchor" id="gga023420f30fec7d4b187fc98f4fd2a55da0b263e2237593103d5e9004e935c66af"></a>PTX_LOAD_CS</em>&nbsp;</td><td class="fielddoc">
<p>Cache streaming (likely to be accessed once) </p>
</td></tr>
<tr><td class="fieldname"><em><a class="anchor" id="gga023420f30fec7d4b187fc98f4fd2a55da05ee1b160fa298ef4b2578a9df1c1350"></a>PTX_LOAD_CV</em>&nbsp;</td><td class="fielddoc">
<p>Cache as volatile (including cached system lines) </p>
</td></tr>
<tr><td class="fieldname"><em><a class="anchor" id="gga023420f30fec7d4b187fc98f4fd2a55dae8ca2d6545712389c0578224f214913d"></a>PTX_LOAD_LDG</em>&nbsp;</td><td class="fielddoc">
<p>Cache as texture. </p>
</td></tr>
<tr><td class="fieldname"><em><a class="anchor" id="gga023420f30fec7d4b187fc98f4fd2a55dae4cbe986a2413b418ec83e8bb153b990"></a>PTX_LOAD_VS</em>&nbsp;</td><td class="fielddoc">
<p>Volatile shared. </p>
</td></tr>
</table>

</div>
</div>
<a class="anchor" id="gae9c7d6a6af7104f528509182ac9c9da2"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group___simt_utils.html#gae9c7d6a6af7104f528509182ac9c9da2">cub::PtxStoreModifier</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Enumeration of PTX cache-modifiers for memory store operations. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><em><a class="anchor" id="ggae9c7d6a6af7104f528509182ac9c9da2a5437dabe5d300b7188dbb42132363c05"></a>PTX_STORE_NONE</em>&nbsp;</td><td class="fielddoc">
<p>Default (no modifier) </p>
</td></tr>
<tr><td class="fieldname"><em><a class="anchor" id="ggae9c7d6a6af7104f528509182ac9c9da2a2d57d44c3dbebbae63abcc3ccb80a412"></a>PTX_STORE_WB</em>&nbsp;</td><td class="fielddoc">
<p>Cache write-back all coherent levels. </p>
</td></tr>
<tr><td class="fieldname"><em><a class="anchor" id="ggae9c7d6a6af7104f528509182ac9c9da2a95a2bc222f2adce9dd2d0251f53e1d91"></a>PTX_STORE_CG</em>&nbsp;</td><td class="fielddoc">
<p>Cache at global level. </p>
</td></tr>
<tr><td class="fieldname"><em><a class="anchor" id="ggae9c7d6a6af7104f528509182ac9c9da2ac08bd33e1c4694ccdb899dd9bdef9c96"></a>PTX_STORE_CS</em>&nbsp;</td><td class="fielddoc">
<p>Cache streaming (likely to be accessed once) </p>
</td></tr>
<tr><td class="fieldname"><em><a class="anchor" id="ggae9c7d6a6af7104f528509182ac9c9da2a8d07fc5099d72afdc46b817d566d3df8"></a>PTX_STORE_WT</em>&nbsp;</td><td class="fielddoc">
<p>Cache write-through (to system memory) </p>
</td></tr>
<tr><td class="fieldname"><em><a class="anchor" id="ggae9c7d6a6af7104f528509182ac9c9da2adee47f52a9358d88446393c5affd11aa"></a>PTX_STORE_VS</em>&nbsp;</td><td class="fielddoc">
<p>Volatile shared. </p>
</td></tr>
</table>

</div>
</div>
<h2 class="groupheader">Function Documentation</h2>
<a class="anchor" id="ga2ece00cc00c1d3269ee79ddf60d15457"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;PtxLoadModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename InputIterator &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockLoadDirect </td>
          <td>(</td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD]&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load a tile of items across a threadblock directly using the specified cache modifier. </p>
<p>The aggregate tile of items is assumed to be partitioned evenly across threads in "blocked" fashion with thread<sub><em>i</em></sub> owning the <em>i</em><sup>th</sup> segment of consecutive elements.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">MODIFIER</td><td><a class="el" href="group___simt_utils.html#ga023420f30fec7d4b187fc98f4fd2a55d" title="Enumeration of PTX cache-modifiers for memory load operations.">cub::PtxLoadModifier</a> cache modifier. </td></tr>
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to load. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> The input iterator type (may be a simple pointer type). </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base input iterator for loading from </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">items</td><td>Data to load </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga51495fa39938ecf57056d4ca6f0260de"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , int ITEMS_PER_THREAD, typename InputIterator &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockLoadDirect </td>
          <td>(</td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD]&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load a tile of items across a threadblock directly. </p>
<p>The aggregate tile of items is assumed to be partitioned evenly across threads in "blocked" fashion with thread<sub><em>i</em></sub> owning the <em>i</em><sup>th</sup> segment of consecutive elements.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to load. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> The input iterator type (may be a simple pointer type). </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base input iterator for loading from </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">items</td><td>Data to load </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga01e0a2d42d5b20aab660815c5cf258a0"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;PtxLoadModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename InputIterator , typename SizeT &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockLoadDirect </td>
          <td>(</td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const SizeT &amp;&#160;</td>
          <td class="paramname"><em>guarded_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD]&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load a tile of items across a threadblock directly using the specified cache modifier, guarded by range. </p>
<p>The aggregate tile of items is assumed to be partitioned evenly across threads in "blocked" fashion with thread<sub><em>i</em></sub> owning the <em>i</em><sup>th</sup> segment of consecutive elements.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">MODIFIER</td><td><a class="el" href="group___simt_utils.html#ga023420f30fec7d4b187fc98f4fd2a55d" title="Enumeration of PTX cache-modifiers for memory load operations.">cub::PtxLoadModifier</a> cache modifier. </td></tr>
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to load. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> The input iterator type (may be a simple pointer type). </td></tr>
    <tr><td class="paramname">SizeT</td><td><b>[inferred]</b> Integer type for offsets </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base input iterator for loading from </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">guarded_items</td><td>Number of valid items in the tile </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">items</td><td>Data to load </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="gaac537b6a8c9caaae1e6e77e9717e9541"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , int ITEMS_PER_THREAD, typename InputIterator , typename SizeT &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockLoadDirect </td>
          <td>(</td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const SizeT &amp;&#160;</td>
          <td class="paramname"><em>guarded_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD]&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load a tile of items across a threadblock directly, guarded by range. </p>
<p>The aggregate tile of items is assumed to be partitioned evenly across threads in "blocked" fashion with thread<sub><em>i</em></sub> owning the <em>i</em><sup>th</sup> segment of consecutive elements.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to load. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> The input iterator type (may be a simple pointer type). </td></tr>
    <tr><td class="paramname">SizeT</td><td><b>[inferred]</b> Integer type for offsets </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base input iterator for loading from </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">guarded_items</td><td>Number of valid items in the tile </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">items</td><td>Data to load </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="gae910789e82acd344d6f5a4cc50beef03"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;PtxLoadModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename InputIterator , typename SizeT &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockLoadDirect </td>
          <td>(</td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const SizeT &amp;&#160;</td>
          <td class="paramname"><em>guarded_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T&#160;</td>
          <td class="paramname"><em>oob_default</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD]&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load a tile of items across a threadblock directly using the specified cache modifier, guarded by range, with assignment for out-of-bound elements. </p>
<p>The aggregate tile of items is assumed to be partitioned evenly across threads in "blocked" fashion with thread<sub><em>i</em></sub> owning the <em>i</em><sup>th</sup> segment of consecutive elements.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">MODIFIER</td><td><a class="el" href="group___simt_utils.html#ga023420f30fec7d4b187fc98f4fd2a55d" title="Enumeration of PTX cache-modifiers for memory load operations.">cub::PtxLoadModifier</a> cache modifier. </td></tr>
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to load. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> The input iterator type (may be a simple pointer type). </td></tr>
    <tr><td class="paramname">SizeT</td><td><b>[inferred]</b> Integer type for offsets </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base input iterator for loading from </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">guarded_items</td><td>Number of valid items in the tile </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">oob_default</td><td>Default value to assign out-of-bound items </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">items</td><td>Data to load </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="gac20fbd7aaa120e661575fe6e8028a015"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , int ITEMS_PER_THREAD, typename InputIterator , typename SizeT &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockLoadDirect </td>
          <td>(</td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const SizeT &amp;&#160;</td>
          <td class="paramname"><em>guarded_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T&#160;</td>
          <td class="paramname"><em>oob_default</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD]&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load a tile of items across a threadblock directly, guarded by range, with assignment for out-of-bound elements. </p>
<p>The aggregate tile of items is assumed to be partitioned evenly across threads in "blocked" fashion with thread<sub><em>i</em></sub> owning the <em>i</em><sup>th</sup> segment of consecutive elements.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to load. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> The input iterator type (may be a simple pointer type). </td></tr>
    <tr><td class="paramname">SizeT</td><td><b>[inferred]</b> Integer type for offsets </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base input iterator for loading from </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">guarded_items</td><td>Number of valid items in the tile </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">oob_default</td><td>Default value to assign out-of-bound items </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">items</td><td>Data to load </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga10442f4a83e49fb4a414ce6ce9234b79"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;PtxLoadModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename InputIterator &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockLoadDirectStriped </td>
          <td>(</td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>stride</em> = <code>blockDim.x</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load striped tile directly using the specified cache modifier. </p>
<p>The aggregate tile of items is assumed to be partitioned across threads in "striped" fashion, i.e., the <code>ITEMS_PER_THREAD</code> items owned by each thread have logical stride <code>BLOCK_THREADS</code> between them.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">MODIFIER</td><td><a class="el" href="group___simt_utils.html#ga023420f30fec7d4b187fc98f4fd2a55d" title="Enumeration of PTX cache-modifiers for memory load operations.">cub::PtxLoadModifier</a> cache modifier. </td></tr>
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to load. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> The input iterator type (may be a simple pointer type). </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base input iterator for loading from </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">items</td><td>Data to load </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td><b>[optional]</b> Stripe stride. Default is the width of the threadblock. More efficient code can be generated if a compile-time-constant (e.g., BLOCK_THREADS) is supplied. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga74f3768367f80c79037b3e77c13bf4bc"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , int ITEMS_PER_THREAD, typename InputIterator &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockLoadDirectStriped </td>
          <td>(</td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>stride</em> = <code>blockDim.x</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load striped tile directly. </p>
<p>The aggregate tile of items is assumed to be partitioned across threads in "striped" fashion, i.e., the <code>ITEMS_PER_THREAD</code> items owned by each thread have logical stride <code>BLOCK_THREADS</code> between them.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">MODIFIER</td><td><a class="el" href="group___simt_utils.html#ga023420f30fec7d4b187fc98f4fd2a55d" title="Enumeration of PTX cache-modifiers for memory load operations.">cub::PtxLoadModifier</a> cache modifier. </td></tr>
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to load. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> The input iterator type (may be a simple pointer type). </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base input iterator for loading from </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">items</td><td>Data to load </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td><b>[optional]</b> Stripe stride. Default is the width of the threadblock. More efficient code can be generated if a compile-time-constant (e.g., BLOCK_THREADS) is supplied. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga405e4ed36717a6d2c0584578ab94923a"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;PtxLoadModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename InputIterator , typename SizeT &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockLoadDirectStriped </td>
          <td>(</td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const SizeT &amp;&#160;</td>
          <td class="paramname"><em>guarded_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>stride</em> = <code>blockDim.x</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load striped directly tile using the specified cache modifier, guarded by range. </p>
<p>The aggregate tile of items is assumed to be partitioned across threads in "striped" fashion, i.e., the <code>ITEMS_PER_THREAD</code> items owned by each thread have logical stride <code>BLOCK_THREADS</code> between them.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">BLOCK_THREADS</td><td>The threadblock size in threads </td></tr>
    <tr><td class="paramname">MODIFIER</td><td><a class="el" href="group___simt_utils.html#ga023420f30fec7d4b187fc98f4fd2a55d" title="Enumeration of PTX cache-modifiers for memory load operations.">cub::PtxLoadModifier</a> cache modifier. </td></tr>
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to load. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> The input iterator type (may be a simple pointer type). </td></tr>
    <tr><td class="paramname">SizeT</td><td><b>[inferred]</b> Integer type for offsets </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base input iterator for loading from </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">guarded_items</td><td>Number of valid items in the tile </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">items</td><td>Data to load </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td><b>[optional]</b> Stripe stride. Default is the width of the threadblock. More efficient code can be generated if a compile-time-constant (e.g., BLOCK_THREADS) is supplied. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga7ba15be704f5aa7c7db809a66af43160"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , int ITEMS_PER_THREAD, typename InputIterator , typename SizeT &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockLoadDirectStriped </td>
          <td>(</td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const SizeT &amp;&#160;</td>
          <td class="paramname"><em>guarded_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>stride</em> = <code>blockDim.x</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load striped tile directly, guarded by range. </p>
<p>The aggregate tile of items is assumed to be partitioned across threads in "striped" fashion, i.e., the <code>ITEMS_PER_THREAD</code> items owned by each thread have logical stride <code>BLOCK_THREADS</code> between them.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to load. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> The input iterator type (may be a simple pointer type). </td></tr>
    <tr><td class="paramname">SizeT</td><td><b>[inferred]</b> Integer type for offsets </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base input iterator for loading from </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">guarded_items</td><td>Number of valid items in the tile </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">items</td><td>Data to load </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td><b>[optional]</b> Stripe stride. Default is the width of the threadblock. More efficient code can be generated if a compile-time-constant (e.g., BLOCK_THREADS) is supplied. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="gabf20f04ee43adc4661429a7902f71911"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;PtxLoadModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename InputIterator , typename SizeT &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockLoadDirectStriped </td>
          <td>(</td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const SizeT &amp;&#160;</td>
          <td class="paramname"><em>guarded_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T&#160;</td>
          <td class="paramname"><em>oob_default</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>stride</em> = <code>blockDim.x</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load striped directly tile using the specified cache modifier, guarded by range, with assignment for out-of-bound elements. </p>
<p>The aggregate tile of items is assumed to be partitioned across threads in "striped" fashion, i.e., the <code>ITEMS_PER_THREAD</code> items owned by each thread have logical stride <code>BLOCK_THREADS</code> between them.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">MODIFIER</td><td><a class="el" href="group___simt_utils.html#ga023420f30fec7d4b187fc98f4fd2a55d" title="Enumeration of PTX cache-modifiers for memory load operations.">cub::PtxLoadModifier</a> cache modifier. </td></tr>
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to load. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> The input iterator type (may be a simple pointer type). </td></tr>
    <tr><td class="paramname">SizeT</td><td><b>[inferred]</b> Integer type for offsets </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base input iterator for loading from </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">guarded_items</td><td>Number of valid items in the tile </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">oob_default</td><td>Default value to assign out-of-bound items </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">items</td><td>Data to load </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td><b>[optional]</b> Stripe stride. Default is the width of the threadblock. More efficient code can be generated if a compile-time-constant (e.g., BLOCK_THREADS) is supplied. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="gaf826ded39a7e107a5f15416d4b147be0"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , int ITEMS_PER_THREAD, typename InputIterator , typename SizeT &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockLoadDirectStriped </td>
          <td>(</td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const SizeT &amp;&#160;</td>
          <td class="paramname"><em>guarded_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T&#160;</td>
          <td class="paramname"><em>oob_default</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>stride</em> = <code>blockDim.x</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load striped tile directly, guarded by range, with assignment for out-of-bound elements. </p>
<p>The aggregate tile of items is assumed to be partitioned across threads in "striped" fashion, i.e., the <code>ITEMS_PER_THREAD</code> items owned by each thread have logical stride <code>BLOCK_THREADS</code> between them.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to load. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">InputIterator</td><td><b>[inferred]</b> The input iterator type (may be a simple pointer type). </td></tr>
    <tr><td class="paramname">SizeT</td><td><b>[inferred]</b> Integer type for offsets </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base input iterator for loading from </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">guarded_items</td><td>Number of valid items in the tile </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">oob_default</td><td>Default value to assign out-of-bound items </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">items</td><td>Data to load </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td><b>[optional]</b> Stripe stride. Default is the width of the threadblock. More efficient code can be generated if a compile-time-constant (e.g., BLOCK_THREADS) is supplied. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="gaea8200ef976bb588c569e039ea79005c"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;PtxLoadModifier MODIFIER, typename T , int ITEMS_PER_THREAD&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockLoadVectorized </td>
          <td>(</td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>block_ptr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD]&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load a tile of items across a threadblock directly using the specified cache modifier. </p>
<p>The aggregate tile of items is assumed to be partitioned evenly across threads in "blocked" fashion with thread<sub><em>i</em></sub> owning the <em>i</em><sup>th</sup> segment of consecutive elements.</p>
<dl class="section user"><dt></dt><dd>The following conditions will prevent vectorization and loading will fall back to <a class="el" href="namespacecub.html#a70f1d3c7536d858d49b896e937d25290a2d4d8900d7e697e9dac4062e97d3d835">cub::BLOCK_LOAD_DIRECT</a>:<ul>
<li><code>ITEMS_PER_THREAD</code> is odd</li>
<li>The <code>InputIterator</code> is not a simple pointer type</li>
<li>The input offset (<code>block_ptr</code> + <code>block_offset</code>) is not quad-aligned</li>
<li>The data type <code>T</code> is not a built-in primitive or CUDA vector type (e.g., <code>short</code>, <code>int2</code>, <code>double</code>, <code>float2</code>, etc.)</li>
</ul>
</dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">MODIFIER</td><td><a class="el" href="group___simt_utils.html#ga023420f30fec7d4b187fc98f4fd2a55d" title="Enumeration of PTX cache-modifiers for memory load operations.">cub::PtxLoadModifier</a> cache modifier. </td></tr>
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to load. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">SizeT</td><td><b>[inferred]</b> Integer type for offsets </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_ptr</td><td>Input pointer for loading from </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">items</td><td>Data to load </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="gab1a8ffc7fe70a636a3d09403344cfced"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , int ITEMS_PER_THREAD&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockLoadVectorized </td>
          <td>(</td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>block_ptr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD]&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Load a tile of items across a threadblock directly. </p>
<p>The aggregate tile of items is assumed to be partitioned evenly across threads in "blocked" fashion with thread<sub><em>i</em></sub> owning the <em>i</em><sup>th</sup> segment of consecutive elements.</p>
<dl class="section user"><dt></dt><dd>The following conditions will prevent vectorization and loading will fall back to <a class="el" href="namespacecub.html#a70f1d3c7536d858d49b896e937d25290a2d4d8900d7e697e9dac4062e97d3d835">cub::BLOCK_LOAD_DIRECT</a>:<ul>
<li><code>ITEMS_PER_THREAD</code> is odd</li>
<li>The <code>InputIterator</code> is not a simple pointer type</li>
<li>The input offset (<code>block_ptr</code> + <code>block_offset</code>) is not quad-aligned</li>
<li>The data type <code>T</code> is not a built-in primitive or CUDA vector type (e.g., <code>short</code>, <code>int2</code>, <code>double</code>, <code>float2</code>, etc.)</li>
</ul>
</dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to load. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_ptr</td><td>Input pointer for loading from </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">items</td><td>Data to load </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="gaa8f12f02c082f8d689100b8ac88f8f61"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;PtxStoreModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename OutputIterator &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockStoreDirect </td>
          <td>(</td>
          <td class="paramtype">OutputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD]&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Store a tile of items across a threadblock directly using the specified cache modifier. </p>
<p>The aggregate tile of items is assumed to be partitioned evenly across threads in <em>blocked</em> arrangement with thread<sub><em>i</em></sub> owning the <em>i</em><sup>th</sup> segment of consecutive elements.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">MODIFIER</td><td><a class="el" href="group___simt_utils.html#gae9c7d6a6af7104f528509182ac9c9da2" title="Enumeration of PTX cache-modifiers for memory store operations.">cub::PtxStoreModifier</a> cache modifier. </td></tr>
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to store. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">OutputIterator</td><td><b>[inferred]</b> The output iterator type (may be a simple pointer type). </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base output iterator for storing to </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">items</td><td>Data to store </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga2d52e8ce92c8bc044898cc289a7e96b4"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , int ITEMS_PER_THREAD, typename OutputIterator &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockStoreDirect </td>
          <td>(</td>
          <td class="paramtype">OutputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD]&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Store a tile of items across a threadblock directly. </p>
<p>The aggregate tile of items is assumed to be partitioned evenly across threads in <em>blocked</em> arrangement with thread<sub><em>i</em></sub> owning the <em>i</em><sup>th</sup> segment of consecutive elements.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to store. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">OutputIterator</td><td><b>[inferred]</b> The output iterator type (may be a simple pointer type). </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base output iterator for storing to </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">items</td><td>Data to store </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga8b5f82ad8487072b6cc80b312db1962d"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;PtxStoreModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename OutputIterator , typename SizeT &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockStoreDirect </td>
          <td>(</td>
          <td class="paramtype">OutputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const SizeT &amp;&#160;</td>
          <td class="paramname"><em>guarded_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD]&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Store a tile of items across a threadblock directly using the specified cache modifier, guarded by range. </p>
<p>The aggregate tile of items is assumed to be partitioned evenly across threads in <em>blocked</em> arrangement with thread<sub><em>i</em></sub> owning the <em>i</em><sup>th</sup> segment of consecutive elements.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">MODIFIER</td><td><a class="el" href="group___simt_utils.html#gae9c7d6a6af7104f528509182ac9c9da2" title="Enumeration of PTX cache-modifiers for memory store operations.">cub::PtxStoreModifier</a> cache modifier. </td></tr>
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to store. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">OutputIterator</td><td><b>[inferred]</b> The output iterator type (may be a simple pointer type). </td></tr>
    <tr><td class="paramname">SizeT</td><td><b>[inferred]</b> Integer type for offsets </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base output iterator for storing to </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">guarded_items</td><td>Number of valid items in the tile </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">items</td><td>Data to store </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga34a623c83894408f4f05ceb788d5ac92"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , int ITEMS_PER_THREAD, typename OutputIterator , typename SizeT &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockStoreDirect </td>
          <td>(</td>
          <td class="paramtype">OutputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const SizeT &amp;&#160;</td>
          <td class="paramname"><em>guarded_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD]&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Store a tile of items across a threadblock directly, guarded by range. </p>
<p>The aggregate tile of items is assumed to be partitioned evenly across threads in <em>blocked</em> arrangement with thread<sub><em>i</em></sub> owning the <em>i</em><sup>th</sup> segment of consecutive elements.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to store. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">OutputIterator</td><td><b>[inferred]</b> The output iterator type (may be a simple pointer type). </td></tr>
    <tr><td class="paramname">SizeT</td><td><b>[inferred]</b> Integer type for offsets </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base output iterator for storing to </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">guarded_items</td><td>Number of valid items in the tile </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">items</td><td>Data to store </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="gaa18341f23a5d00c1b148e0013a9cc637"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;PtxStoreModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename OutputIterator &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockStoreDirectStriped </td>
          <td>(</td>
          <td class="paramtype">OutputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>stride</em> = <code>blockDim.x</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Store striped tile directly using the specified cache modifier. </p>
<p>The aggregate tile of items is assumed to be partitioned across threads in "striped" arrangement, i.e., the <code>ITEMS_PER_THREAD</code> items owned by each thread have logical stride <code>BLOCK_THREADS</code> between them.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">MODIFIER</td><td><a class="el" href="group___simt_utils.html#gae9c7d6a6af7104f528509182ac9c9da2" title="Enumeration of PTX cache-modifiers for memory store operations.">cub::PtxStoreModifier</a> cache modifier. </td></tr>
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to store. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">OutputIterator</td><td><b>[inferred]</b> The output iterator type (may be a simple pointer type). </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base output iterator for storing to </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">items</td><td>Data to store </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td><b>[optional]</b> Stripe stride. Default is the width of the threadblock. More efficient code can be generated if a compile-time-constant (e.g., BLOCK_THREADS) is supplied. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="gaed26402e843c84978ce85da24819ebeb"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , int ITEMS_PER_THREAD, typename OutputIterator &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockStoreDirectStriped </td>
          <td>(</td>
          <td class="paramtype">OutputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>stride</em> = <code>blockDim.x</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Store striped tile directly. </p>
<p>The aggregate tile of items is assumed to be partitioned across threads in <em>striped</em> arrangement, i.e., the <code>ITEMS_PER_THREAD</code> items owned by each thread have logical stride <code>BLOCK_THREADS</code> between them.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">MODIFIER</td><td><a class="el" href="group___simt_utils.html#gae9c7d6a6af7104f528509182ac9c9da2" title="Enumeration of PTX cache-modifiers for memory store operations.">cub::PtxStoreModifier</a> cache modifier. </td></tr>
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to store. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">OutputIterator</td><td><b>[inferred]</b> The output iterator type (may be a simple pointer type). </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base output iterator for storing to </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">items</td><td>Data to store </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td><b>[optional]</b> Stripe stride. Default is the width of the threadblock. More efficient code can be generated if a compile-time-constant (e.g., BLOCK_THREADS) is supplied. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="gadcef89bcc6b3c66e1fa1267c15b08a78"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;PtxStoreModifier MODIFIER, typename T , int ITEMS_PER_THREAD, typename OutputIterator , typename SizeT &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockStoreDirectStriped </td>
          <td>(</td>
          <td class="paramtype">OutputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const SizeT &amp;&#160;</td>
          <td class="paramname"><em>guarded_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>stride</em> = <code>blockDim.x</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Store striped directly tile using the specified cache modifier, guarded by range</p>
<p>The aggregate tile of items is assumed to be partitioned across threads in <em>striped</em> arrangement, i.e., the <code>ITEMS_PER_THREAD</code> items owned by each thread have logical stride <code>BLOCK_THREADS</code> between them.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">MODIFIER</td><td><a class="el" href="group___simt_utils.html#gae9c7d6a6af7104f528509182ac9c9da2" title="Enumeration of PTX cache-modifiers for memory store operations.">cub::PtxStoreModifier</a> cache modifier. </td></tr>
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to store. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">OutputIterator</td><td><b>[inferred]</b> The output iterator type (may be a simple pointer type). </td></tr>
    <tr><td class="paramname">SizeT</td><td><b>[inferred]</b> Integer type for offsets </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base output iterator for storing to </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">guarded_items</td><td>Number of valid items in the tile </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">items</td><td>Data to store </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td><b>[optional]</b> Stripe stride. Default is the width of the threadblock. More efficient code can be generated if a compile-time-constant (e.g., BLOCK_THREADS) is supplied. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga75150e5519f86c1054d7a7584e1a4f23"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , int ITEMS_PER_THREAD, typename OutputIterator , typename SizeT &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockStoreDirectStriped </td>
          <td>(</td>
          <td class="paramtype">OutputIterator&#160;</td>
          <td class="paramname"><em>block_itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const SizeT &amp;&#160;</td>
          <td class="paramname"><em>guarded_items</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD], </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>stride</em> = <code>blockDim.x</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Store striped tile directly, guarded by range. </p>
<p>The aggregate tile of items is assumed to be partitioned across threads in <em>striped</em> arrangement, i.e., the <code>ITEMS_PER_THREAD</code> items owned by each thread have logical stride <code>BLOCK_THREADS</code> between them.</p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to store. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
    <tr><td class="paramname">OutputIterator</td><td><b>[inferred]</b> The output iterator type (may be a simple pointer type). </td></tr>
    <tr><td class="paramname">SizeT</td><td><b>[inferred]</b> Integer type for offsets </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_itr</td><td>The threadblock's base output iterator for storing to </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">guarded_items</td><td>Number of valid items in the tile </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">items</td><td>Data to store </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">stride</td><td><b>[optional]</b> Stripe stride. Default is the width of the threadblock. More efficient code can be generated if a compile-time-constant (e.g., BLOCK_THREADS) is supplied. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga013c3ab8214854f45e8d678958e7dde9"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;PtxStoreModifier MODIFIER, typename T , int ITEMS_PER_THREAD&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockStoreVectorized </td>
          <td>(</td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>block_ptr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD]&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Store a tile of items across a threadblock directly using the specified cache modifier. </p>
<p>The aggregate tile of items is assumed to be partitioned evenly across threads in <em>blocked</em> arrangement with thread<sub><em>i</em></sub> owning the <em>i</em><sup>th</sup> segment of consecutive elements.</p>
<dl class="section user"><dt></dt><dd>The following conditions will prevent vectorization and storing will fall back to <a class="el" href="namespacecub.html#aaaa9ee8c8a57c6607909c110affd189ea9b8dcc7b6b06bcfc24af4f499523b880">cub::BLOCK_STORE_DIRECT</a>:<ul>
<li><code>ITEMS_PER_THREAD</code> is odd</li>
<li>The <code>OutputIterator</code> is not a simple pointer type</li>
<li>The input offset (<code>block_ptr</code> + <code>block_offset</code>) is not quad-aligned</li>
<li>The data type <code>T</code> is not a built-in primitive or CUDA vector type (e.g., <code>short</code>, <code>int2</code>, <code>double</code>, <code>float2</code>, etc.)</li>
</ul>
</dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">MODIFIER</td><td><a class="el" href="group___simt_utils.html#gae9c7d6a6af7104f528509182ac9c9da2" title="Enumeration of PTX cache-modifiers for memory store operations.">cub::PtxStoreModifier</a> cache modifier. </td></tr>
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to store. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_ptr</td><td>Input pointer for storing from </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">items</td><td>Data to store </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga5db0cef20c11ea62aef484c587c4e064"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T , int ITEMS_PER_THREAD&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::BlockStoreVectorized </td>
          <td>(</td>
          <td class="paramtype">T *&#160;</td>
          <td class="paramname"><em>block_ptr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T(&amp;)&#160;</td>
          <td class="paramname"><em>items</em>[ITEMS_PER_THREAD]&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Store a tile of items across a threadblock directly. </p>
<p>The aggregate tile of items is assumed to be partitioned evenly across threads in <em>blocked</em> arrangement with thread<sub><em>i</em></sub> owning the <em>i</em><sup>th</sup> segment of consecutive elements.</p>
<dl class="section user"><dt></dt><dd>The following conditions will prevent vectorization and storing will fall back to <a class="el" href="namespacecub.html#aaaa9ee8c8a57c6607909c110affd189ea9b8dcc7b6b06bcfc24af4f499523b880">cub::BLOCK_STORE_DIRECT</a>:<ul>
<li><code>ITEMS_PER_THREAD</code> is odd</li>
<li>The <code>OutputIterator</code> is not a simple pointer type</li>
<li>The input offset (<code>block_ptr</code> + <code>block_offset</code>) is not quad-aligned</li>
<li>The data type <code>T</code> is not a built-in primitive or CUDA vector type (e.g., <code>short</code>, <code>int2</code>, <code>double</code>, <code>float2</code>, etc.)</li>
</ul>
</dd></dl>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td><b>[inferred]</b> The data type to store. </td></tr>
    <tr><td class="paramname">ITEMS_PER_THREAD</td><td><b>[inferred]</b> The number of consecutive items partitioned onto each thread. </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">block_ptr</td><td>Input pointer for storing from </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">items</td><td>Data to store </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga1e390b9fee4c8012a021d49d9b76b1e8"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;PtxLoadModifier MODIFIER, typename InputIterator &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ std::iterator_traits&lt;InputIterator&gt;::value_type cub::ThreadLoad </td>
          <td>(</td>
          <td class="paramtype">InputIterator&#160;</td>
          <td class="paramname"><em>itr</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Thread utility for reading memory using <a class="el" href="group___simt_utils.html#ga023420f30fec7d4b187fc98f4fd2a55d" title="Enumeration of PTX cache-modifiers for memory load operations.">cub::PtxLoadModifier</a> cache modifiers. </p>
<p>Cache modifiers will only be effected for built-in types (i.e., C++ primitives and CUDA vector-types).</p>
<p>For example: </p>
<dl class="section user"><dt></dt><dd><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;cub.cuh&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// 32-bit load using cache-global modifier:</span></div>
<div class="line"><span class="keywordtype">int</span> *d_in;</div>
<div class="line"><span class="keywordtype">int</span> val = cub::ThreadLoad&lt;cub::PTX_LOAD_CA&gt;(d_in + threadIdx.x);</div>
<div class="line"></div>
<div class="line"><span class="comment">// 16-bit load using default modifier</span></div>
<div class="line"><span class="keywordtype">short</span> *d_in;</div>
<div class="line"><span class="keywordtype">short</span> val = cub::ThreadLoad&lt;cub::PTX_LOAD_NONE&gt;(d_in + threadIdx.x);</div>
<div class="line"></div>
<div class="line"><span class="comment">// 256-bit load using cache-volatile modifier</span></div>
<div class="line">double4 *d_in;</div>
<div class="line">double4 val = cub::ThreadLoad&lt;cub::PTX_LOAD_CV&gt;(d_in + threadIdx.x);</div>
<div class="line"></div>
<div class="line"><span class="comment">// 96-bit load using default cache modifier (ignoring PTX_LOAD_CS)</span></div>
<div class="line"><span class="keyword">struct </span>TestFoo { <span class="keywordtype">bool</span> a; <span class="keywordtype">short</span> b; };</div>
<div class="line">TestFoo *d_struct;</div>
<div class="line">TestFoo val = cub::ThreadLoad&lt;cub::PTX_LOAD_CS&gt;(d_in + threadIdx.x);</div>
</div><!-- fragment --> </dd></dl>

</div>
</div>
<a class="anchor" id="gad117ecb99b9230a032971b0ac08ca6dc"></a>
<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;PtxStoreModifier MODIFIER, typename OutputIterator , typename T &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">__device__ __forceinline__ void cub::ThreadStore </td>
          <td>(</td>
          <td class="paramtype">OutputIterator&#160;</td>
          <td class="paramname"><em>itr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const T &amp;&#160;</td>
          <td class="paramname"><em>val</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Thread utility for writing memory using <a class="el" href="group___simt_utils.html#gae9c7d6a6af7104f528509182ac9c9da2" title="Enumeration of PTX cache-modifiers for memory store operations.">cub::PtxStoreModifier</a> cache modifiers. </p>
<p>Cache modifiers will only be effected for built-in types (i.e., C++ primitives and CUDA vector-types).</p>
<p>For example: </p>
<dl class="section user"><dt></dt><dd><div class="fragment"><div class="line"><span class="preprocessor">#include &lt;cub.cuh&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="comment">// 32-bit store using cache-global modifier:</span></div>
<div class="line"><span class="keywordtype">int</span> *d_out;</div>
<div class="line"><span class="keywordtype">int</span> val;</div>
<div class="line">cub::ThreadStore&lt;cub::PTX_STORE_CG&gt;(d_out + threadIdx.x, val);</div>
<div class="line"></div>
<div class="line"><span class="comment">// 16-bit store using default modifier</span></div>
<div class="line"><span class="keywordtype">short</span> *d_out;</div>
<div class="line"><span class="keywordtype">short</span> val;</div>
<div class="line">cub::ThreadStore&lt;cub::PTX_STORE_NONE&gt;(d_out + threadIdx.x, val);</div>
<div class="line"></div>
<div class="line"><span class="comment">// 256-bit store using write-through modifier</span></div>
<div class="line">double4 *d_out;</div>
<div class="line">double4 val;</div>
<div class="line">cub::ThreadStore&lt;cub::PTX_STORE_WT&gt;(d_out + threadIdx.x, val);</div>
<div class="line"></div>
<div class="line"><span class="comment">// 96-bit store using default cache modifier (ignoring PTX_STORE_CS)</span></div>
<div class="line"><span class="keyword">struct </span>TestFoo { <span class="keywordtype">bool</span> a; <span class="keywordtype">short</span> b; };</div>
<div class="line">TestFoo *d_struct;</div>
<div class="line">TestFoo val;</div>
<div class="line">cub::ThreadStore&lt;cub::PTX_STORE_CS&gt;(d_out + threadIdx.x, val);</div>
</div><!-- fragment --> </dd></dl>

</div>
</div>
</div><!-- contents -->
<!-- HTML footer for doxygen 1.8.3.1-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Sat Mar 9 2013 04:59:40 for CUB by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.3.1
<br>
&copy; 2013 NVIDIA Corporation
</small></address>
</body>
</html>
